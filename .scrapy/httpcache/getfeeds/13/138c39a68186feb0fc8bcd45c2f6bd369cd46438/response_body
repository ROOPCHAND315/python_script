<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>artificial intelligence | The Walrus</title>
	<atom:link href="https://thewalrus.ca/tag/artificial-intelligence/feed/" rel="self" type="application/rss+xml" />
	<link>https://thewalrus.ca</link>
	<description>Fact-based journalism that sparks the Canadian conversation</description>
	<lastBuildDate>Thu, 26 Oct 2023 20:04:16 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.0.3</generator>

<image>
	<url>https://walrus-assets.s3.amazonaws.com/img/favicon1.ico</url>
	<title>artificial intelligence | The Walrus</title>
	<link>https://thewalrus.ca</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Are AI Companies Ripping Off Writers? Canadian Authors Speak Out</title>
		<link>https://thewalrus.ca/ai-authors-speak-out/</link>
		
		<dc:creator><![CDATA[Various Contributors]]></dc:creator>
		<pubDate>Mon, 09 Oct 2023 10:30:13 +0000</pubDate>
				<category><![CDATA[Books]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[audio]]></category>
		<category><![CDATA[canadian literature]]></category>
		<category><![CDATA[hide-ad]]></category>
		<category><![CDATA[hide-ads]]></category>
		<category><![CDATA[homepage]]></category>
		<category><![CDATA[literature]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=159018</guid>

		`

		<description><![CDATA[Yann Martel, Heather O’Neill, Douglas Coupland, and others weigh in on their books being used to train AI systems]]></description>
		<content:encoded><![CDATA[<img width="1600" height="1067" src="https://walrus-assets.s3.amazonaws.com/img/Rustad_AIAuthors_1800.jpeg" class="webfeedsFeaturedVisual wp-post-image" alt="A photo of a book icon on a screen within a circuit board." style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/Rustad_AIAuthors_1800.jpeg 1600w, https://walrus-assets.s3.amazonaws.com/img/Rustad_AIAuthors_1800-735x490.jpeg 735w, https://walrus-assets.s3.amazonaws.com/img/Rustad_AIAuthors_1800-1536x1024.jpeg 1536w, https://walrus-assets.s3.amazonaws.com/img/Rustad_AIAuthors_1800-1200x800.jpeg 1200w, https://walrus-assets.s3.amazonaws.com/img/Rustad_AIAuthors_1800-348x232.jpeg 348w" sizes="(max-width: 1600px) 100vw, 1600px" /><p><span class="dropcap">O</span><span class="smallcaps">n September 25,</span> an article published by <em>The Atlantic</em>, titled “<a href="https://www.theatlantic.com/technology/archive/2023/09/books3-database-generative-ai-training-copyright-infringement/675363/" rel="noopener" target="_blank">These 183,000 Books Are Fueling the Biggest Fight in Publishing and Tech</a>,” caught my eye. Toward the end of the summer, Alex Reisner, the writer of that piece, had published a series of <a href="https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/" rel="noopener" target="_blank">articles</a> that revealed that a data set of books, called Books3, was among those being used by companies to train their generative artificial intelligence systems. In order to sound like humans, these systems need to be fed text written by humans. </p>
<p>The authors of the books included in this data set received no compensation and no royalties for the use of copyrighted works. As Reisner writes: “These authors spent years thinking, researching, imagining, and writing, and had no idea that their books were being used to train machines that could one day replace them. Meanwhile, the people building and training these machines stand to profit enormously.” Several writers in the United States have launched lawsuits claiming that this amounts to copyright infringement. </p>
<p>In Reisner’s latest article, he included a <a href="https://www.theatlantic.com/technology/archive/2023/09/books3-database-generative-ai-training-copyright-infringement/675363/" rel="noopener" target="_blank">search tool</a>: any author can check whether or not their books are being used without their consent. Seeing that a book I wrote was included in the data set felt not only like a violation of rights but also a plundering, both personal and existential. Reisner sums it up perfectly in the first instalment of the series: “The future promised by AI is written with stolen words.”</p>
<p>Hundreds of titles by Canadian authors, including Alice Munro, Austin Clarke, Leonard Cohen, and Miriam Toews, were listed in Books3. We reached out to some of them to ask how they felt about one or several of their books being included.&mdash;Harley Rustad, author of <em>Big Lonely Doug</em> and <em>Lost in the Valley of Death</em> </p>
<hr>
<ul class="link-list">
<li><a href="https://thewalrus.ca/ai-authors-speak-out#GeorgeMurray"> George Murray </a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#YannMartel">Yann Martel</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#KathrynKuitenbrouwer">Kathryn Kuitenbrouwer</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#HeatherONeill">Heather O’Neill</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#MichaelMelgaard">Michael Melgaard</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#RandyBoyagoda">Randy Boyagoda</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#ClaireCameron">Claire Cameron</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#PashaMalla">Pasha Malla</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#JoanThomas">Joan Thomas</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#SeanMichaels">Sean Michaels</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#AlissaYork">Alissa York</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#WaubgeshigRice">Waubgeshig Rice</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#ElisabethdeMariaffi">Elisabeth de Mariaffi</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#ChristianBok">Christian Bök</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#DouglasCoupland">Douglas Coupland</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#AlixOhlin">Alix Ohlin</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#JohnVaillant">John Vaillant</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#MarkAbley">Mark Abley</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#DavidBezmozgis">David Bezmozgis</a></li>
<li><a href="https://thewalrus.ca/ai-authors-speak-out#KateHarris">Kate Harris</a></li>
<p><a name="GeorgeMurray"></a>
</ul>
<div class="container-small">
<div class="span2">
<hr>
<p>“I was frankly shocked to see a book of mine as part of this data set. It feels invasive. That said, I am already used to this violation&mdash;having found out my work is being photocopied for course packages at major universities in Canada to ‘train’ students. Like the AI corporations, these universities do not remunerate writers, nor do they pay into copyright-protecting organizations like Access Copyright that collect and disseminate funds to authors for use of their work. The key difference here is that at universities, my work is ostensibly being used to teach writing, critical thinking, and communication skills to humans, while at the corporations that train AI, it is being used to create software designed to eliminate writing jobs, mimic and replace human interaction, <a name="YannMartel"></a>and create greater profits for corporations. A student may find something to like in my work and buy future books. An AI will not.”&mdash;George Murray, author of several books of poetry, including <em>Whiteout</em></p>
<p>“The whole point of novels, plays, poems, and essays is to increase our humanity, not reduce it. That comes from one human being reaching out to another. It’s both a creative and a social act. Introducing AI short-circuits that, because AI-generated writing is neither social nor humanly created. So it’s not a question of whether AI generates good or bad writing. After all, there’s plenty of human-crafted writing out there that’s terrible. But it’s still human, it’s still one person’s attempt to say something about the human condition. <a name="KathrynKuitenbrouwer"></a>I’d rather a bad human poem than a robot’s sterling ode.”&mdash;Yann Martel, author of several books, including <em>Life of Pi</em> and <em>The High Mountains of Portugal </em></p>
<p>“Discovering that pirated versions of my novel <em>All the Broken Things</em> were stolen to provide content in the development of generative-AI systems makes me sick to my stomach. The outrage of my intellectual property being pillaged without my consent&mdash;for the purpose of, ultimately, Meta et al.’s capital gain&mdash;is infuriating and deeply upsetting. Canadian writers, publishers, and readers need to stand up against this egregious and unfair usage.”<a name="HeatherONeill"></a>&mdash;Kathryn Kuitenbrouwer, author of several books, including <em>All the Broken Things</em> and <em>Wait Softly Brother</em></p>
<p>“I think books and their authors are inseparable. And the beauty of the relationship between the writer and their work and their readers is what makes novels part of the history of humanity. To steal an author’s voice, which they created out of the ecstatic and punishing moments of their life, is akin to stealing their soul. It’s monstrous.”<a name="MichaelMelgaard"></a>&mdash;Heather O’Neill, author of several books, including <em>When We Lost Our Heads </em>and <em>The Lonely Hearts Hotel</em></p>
<p>“Big tech, again and again, shows itself to be an industry that moves with entitlement and lack of care. While what we’re calling AI is developing into a useful tool, companies that build their programs out of stolen parts can’t be trusted to share the technology in a way that respects the rules and rights of people. The violation of rights goes far beyond writers. Tech companies have been mining us for years with varying degrees of consent (location tracking, facial recognition, and numerous other incidents of using others’ work to train generative AI)&mdash;and I hope <a name="RandyBoyagoda"></a>writers will use this opportunity to join the many ongoing fights to ensure that use of these developing technologies is equitable, both in their creation and their execution.”&mdash;Michael Melgaard, author of <em>Not That Kind of Place</em> and <em>Pallbearing </em></p>
<p>“When I first learned that my books appear in the Books3 data set, I had two strong reactions. The first: I made it! The second: Money? But these are lizard-brain writer reactions (which I do not disavow). In more reflective terms: when I was working on my second novel, <em>Beggar’s Feast</em>, Michael Meyler’s <em>Dictionary of Sri Lankan English</em> was an important sourcebook. Years later, looking something up in the online version of the dictionary, I came across a new citation of the word “talipot,” which the compilers cited as occurring in <em>Beggar’s Feast</em>. I drew on a source and in turn contributed to the source for others to use, as part of a living dynamism that makes possible the growth, evolution, and spread of stories and language. By comparison, the AI system version feels like dead-letter one-way voracity.”<a name="ClaireCameron"></a>&mdash;Randy Boyagoda, author of several books, including <em>Governor of the Northern Province</em> and <em>Beggar’s Feast</em></p>
<p>“As Cormac McCarthy said, ‘Books are made out of books.’ It’s true&mdash;ideas feed each other&mdash;and the system of exchange works when it involves consent, credit, and compensation. Technology is always changing, but those things stay the same. It’s disheartening to see them ignored in this case.”<a name="PashaMalla"></a>&mdash;Claire Cameron, author of <em>The Last Neanderthal</em> and <em>The Bear</em></p>
<p>“I asked ChatGPT how I should feel about it: ‘Ultimately, how Pasha Malla feels about being included in the “Books3” dataset would depend on various factors, including the terms of inclusion, the reputation and purpose of the dataset, and how it aligns with his professional and personal objectives as an author.’”&mdash;Pasha Malla,<a name="JoanThomas"></a> author of several books, including <em>The Withdrawal Method</em> and <em>People Park</em></p>
<p>“Learning that my books are on an AI data set made me think about how much I value fiction as a meeting with another consciousness. The idea of a bot-generated novel&mdash;it’s monstrous. A novel without intentionality or insight or novelty&mdash;that unsettles me more than any breach of my copyright. The degrading of our culture with more crap content.”<a name="SeanMichaels"></a>&mdash;Joan Thomas, author of several books, including <em>Wild Hope </em>and <em>Five Wives</em></p>
<p>“The question of what to do about AI art&mdash;of how to understand that provocation and how to find solidarity with other artists&mdash;is the subject of my recent novel, <em>Do You Remember Being Born?</em> But, for me, the question posed by Books3, as well as other similar training sets (most of which are closed, i.e., secret), isn’t about artificial intelligence at all. It’s about the covert manipulation of my work, and my peers’, for other people’s profit. How do we throw sand in the gears of this new form of exploitation? And, if we can’t, what steps can we take to protect each other from the avarice of those who would grind us up into feather meal? Writing isn’t threatened by large language models&mdash;and some artists will find ways to use them in astonishing work. The real adversary is the same old cast of robbers; we may just need to get more creative to oppose them.”&mdash;Sean Michaels, <a name="AlissaYork"></a>author of <em>Us Conductors </em>and <em>Do You Remember Being Born?</em> </p>
<p>“To begin with, I felt an echoey sense of dread. Imagine, all that work&mdash;all that <em>meaning</em>&mdash;shattered into atoms of code. Don’t we already ‘sound like people’? Must we really innovate ourselves to smithereens? Remember the holodeck? I always pitied those poor star-trekking bastards, kidding themselves they were making love in a meadow while they hurtled through the loneliest reaches of space. The dread ebbed away&mdash;in its place, a blessing that caught me off guard. I felt grateful. For writers and for readers. <a name="WaubgeshigRice"></a>For all that remains steadfastly anti-artificial in my life: real love, real meadows, real art.”&mdash;Alissa York, author of <em>Effigy</em> and <em>Far Cry</em> </p>
<p>“I was disappointed but not surprised to learn that one of my books was found in this data set. Sadly, it seems that nowadays all artistic content is vulnerable to exploitation in the digital realm. I think it’s a good reminder for Indigenous writers to be careful with our people’s stories, especially those that have survived and still persevere in the oral tradition. I believe many of our cultural truths and sagas should remain only in the spoken realm so they’re not abused by outside forces beyond our control. We should definitely keep writing our experiences, but we need to be particularly mindful going forward about what we publish because of how our stories could be manipulated.”<a name="ElisabethdeMariaffi"></a>&mdash;Waubgeshig Rice, author of several books, including <em>Moon of the Crusted Snow</em> and <em>Moon of the Turning Leaves</em></p>
<p>“Finding my books on the Books3 data set was disappointing and disorienting: writing is how I’ve made my life, artistically, and&mdash;this is important&mdash;practically too. I’ve been watching the quick turn to AI with growing concern for over a year&mdash;all the ways it could threaten our literacy as a culture but also the ways it threatens my personal way of making a living. Books and writing are how I pay my mortgage, my children’s tuition, my grocery bill. To see my work so cavalierly stolen and used, without my consent, by corporations eager only to increase their own profits, is frankly terrifying.”&mdash;Elisabeth de Mariaffi,<a name="ChristianBok"></a> author of <em>The Retreat</em> and <em>The Devil You Know</em></p>
<p>“I am honoured to discover that <em>Eunoia</em> appears within the data set of Books3&mdash;a list of 183,000 books, all among ‘the Elect,’ now gone to Heaven and used to train the minds of our futurist machines (which, like any of our children, do not need our permission to become literate).”&mdash;Christian Bök, <a name="DouglasCoupland"></a>whose books include <em>Eunoia</em> and <em>The Xenotext: Book 1</em></p>
<p>“The thing I’ve never seen anyone write or talk about is that it’s not only writers and authors involved here. It’s everyone. If AI gets access to your email, then it’s got you forever. It will know how you actually speak, how you actually write, who you like, what you really think of people, your food and porn and travel preferences. Everything. This can actually be a comfort, because people in your life can speak with you long after you’re dead. So it’s a trade-off.”&mdash;Douglas Coupland, <a name="AlixOhlin"></a>author of several books, including <em>Girlfriend in a Coma</em> and <em>JPod</em></p>
<p>“To me, this particular case isn’t about technology&mdash;it’s about capitalism and labour. A lot of writers I know enjoy playing with AI, and I’ve played with it myself. There are many exciting possibilities for the intersections of art and technology, and it’s not like writers are sitting around using quill pens dipped in ink, refusing to recognize the rapidly changing conditions of our times. But the data set here was gathered without informed consent. The fact that our information infrastructure is clustered in the hands of a few companies, largely without transparency and based on short-term profit making, should concern not just writers but also readers, citizens. We turn online all the time to make sense of the world, and we’re pretty trusting, overall, about what we find there and the mechanisms by which it came to be available. I’m not sure any of us think about that as much as we should.”&mdash;Alix Ohlin, <a name="JohnVaillant"></a>author of several books, including <em>Dual Citizens</em> and <em>The Missing Person</em></p>
<p>“As unsettling, alienating, and violating as this feels, we benefit from, and now expect, this kind of high-speed agglomerating, sorting, and rearranging technology every day. That AI is conceived and enabled by brilliant, ambitious, but immature men bodes ill for our civilization. That it can put us all out of a job is a real possibility, though this disemployment will likely occur in ways far more subtle than the infinite mimicry promised by LLaMA. It’s hard to know how to feel about something so difficult to meaningfully imagine, but I recognize that it is inherently uncontrollable. In this way, AI is the logical cousin to twenty-first-century climate disruption: while we may have unleashed it, no one is ready for it, and our efforts to rein it in will manifest as perpetual catch-up: lunging to grab its tail before it disappears around the next corner.”&mdash;John Vaillant, <a name="MarkAbley"></a>author of several books, including <em>Fire Weather</em> and <em>The Golden Spruce</em></p>
<p>“AI induces a sense of helplessness in me. I feel angry about the ravages of climate change and the burgeoning of fake news. ExxonMobil has earned my fury. Donald Trump has earned my fury. But AI, by its very facelessness, defeats anger. It’s hard to feel anything about an algorithm except a numb dismay. Then I remind myself: AI systems are thieves. I realize the systems don’t care about the quality of my prose and the depth (or shallowness) of my insights. But an impersonal motive doesn’t excuse the theft of language. AI cannot strip writers of imagination. What it <em>can</em> do is scrape away hope.”&mdash;Mark Abley, <a name="DavidBezmozgis"></a>author of several books, including <em>Spoken Here</em> and <em>The Prodigal Tongue</em></p>
<p>“I recall a quote by Trotsky that the goal of communism was to free people to become poets. I realize that the communist project went badly. In the ideal version of AI reality, what is being promised writers and readers in exchange for the lives we lead now? At the level of pure vanity, I am flattered that my books are included in the data set that seems designed to make me redundant. On an aesthetic level, I recoil at the terms Pile and Books3. Big Tech companies are so rich. I know the rich also steal. If they had paid the licence fees, the people who oppose what they are doing would still, fundamentally, oppose it. The theft just makes it gross. Is the prospect of this technology worse than the technology we already have? Will my children, who prefer TikTok to books, be more likely to read books by AI? Is this not perhaps a battle in a greater war that we are already losing?”<a name="KateHarris"></a>&mdash;David Bezmozgis, author of several books, including <em>Free World</em> and <em>Natasha</em></p>
<p>“A book is a consciousness scored on the page. It is the result of years of living and thinking and experimenting and dreaming. And now, for me and so many other authors, it is just another neuron firing in the techno-capitalist mind, stolen from creators for the profit of a select few. They are soul eaters. As authors, we are solitary by nature and vocation, but this might prove our collective downfall in the era of AI. Why aren’t we striking alongside screenwriters and actors, given the mutual threat to our livelihood, our reason for being? Where is our Fran Drescher to lead the charge?”&mdash;Kate Harris, author of <em>Lands of Lost Borders</em></p>The post <a href="https://thewalrus.ca/ai-authors-speak-out/">Are AI Companies Ripping Off Writers? Canadian Authors Speak Out</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
		<item>
		<title>Margaret Atwood Reviews a “Margaret Atwood” Story by AI</title>
		<link>https://thewalrus.ca/margaret-atwood-ai/</link>
		
		<dc:creator><![CDATA[Margaret Atwood]]></dc:creator>
		<pubDate>Thu, 05 Oct 2023 10:30:39 +0000</pubDate>
				<category><![CDATA[Technology]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[audio]]></category>
		<category><![CDATA[hide-ad]]></category>
		<category><![CDATA[hide-ads]]></category>
		<category><![CDATA[homepage]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=158963</guid>

		`

		<description><![CDATA[Plus a poem that a chatbot took ten seconds to write]]></description>
		<content:encoded><![CDATA[<img width="1200" height="800" src="https://walrus-assets.s3.amazonaws.com/img/Atwood_AI_JeffMorgan_Alamy_1800.jpeg" class="webfeedsFeaturedVisual wp-post-image" alt="A photo of Margaret Atwood at The Guardian Hay Festival in 2006 speaking in front of a large projection of her face." loading="lazy" style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/Atwood_AI_JeffMorgan_Alamy_1800.jpeg 1200w, https://walrus-assets.s3.amazonaws.com/img/Atwood_AI_JeffMorgan_Alamy_1800-735x490.jpeg 735w, https://walrus-assets.s3.amazonaws.com/img/Atwood_AI_JeffMorgan_Alamy_1800-348x232.jpeg 348w" sizes="(max-width: 1200px) 100vw, 1200px" /><p><span class="dropcap">M</span><span class="smallcaps">uch handwringing</span> is going on among writers about the impending terrors of generative <a href="https://thewalrus.ca/tag/artificial-intelligence/" rel="noopener" target="_blank">AI</a> and their potentially predatory behaviour. They’re being trained on our pirated books, say the writers, and they don’t chew their food. How can they, since they’re being force-fed every last bit of verbiage their proprietors can filch? Will they just gobble us up like great white sharks, burping out an endless stream of teeth, bones, and ersatz fictions claiming to be by us?  Will they infiltrate themselves into us like the emotionless pod people in <em>Invasion of the Body Snatchers</em> and eat us from the inside out, transforming us into fakes of ourselves and giving pink flowers a bad name? </p>
<p>Are they malevolent aliens, or are they more like human criminals? They certainly can’t be depended on to tell the truth, except maybe about things like airline schedules. But can they write convincing Harlequin Romance novels? Will the real Harlequin Romance writers be done out of their jobs? </p>
<p>AI chatbots cannot dress up in period costume. Or not yet. There’s that. </p>
<ul class="related">
<li><a href="https://thewalrus.ca/ai-is-coming-for-voice-actors-artists-everywhere-should-take-note/">AI Is Coming for Voice Actors. Artists Everywhere Should Take Note</a></li>
<li><a href="https://thewalrus.ca/authors-abandoning-speech-marks/">Why Are So Many Authors Abandoning Speech Marks?</a></li>
<li><a href="https://thewalrus.ca/ai-poetry/">Robots Are Writing Poetry, and Many People Can’t Tell the Difference</a></li>
</ul>
<p>Will they write political speeches? That’s more than likely. Some of them are already hard at it. But will they ever be able to come up with new catchphrases, such as “I did nothing wrong” and “I alone can fix it”? Oh. Sorry. Not so new. </p>
<p>Take heart! Not all is gloom! So far, generative AI chatbots don’t seem able to reflect on what they’re saying, though that in itself wouldn’t differentiate them from some actual human beings. Also, they’re bad at verbal texture, and they have a poor grasp of metaphor and sometimes even of punctuation. Well, they’re learning from us, so why wouldn’t that be true?</p>
<p>You’re still worried, young author? You doubt my word? Here are a couple of recent literary attempts by AI chatbots that ought to reassure you. </p>
<p>The first is a poem, requested by one of the board members of the Pelee Island Bird Observatory&mdash;PIBO&mdash;which counts and evaluates the health of migratory species on an island in Lake Erie. The bird banders and volunteers often have to wade through knee-deep mud and contend with chiggers, mosquitoes, and biting flies. They don’t wear gloves&mdash;they need a fine and gentle touch to handle small birds&mdash;or insect repellant, as that could be toxic. Let’s just say they suffer so that you can continue to enjoy birdsong.</p>
<p>Here is the request made to the chatbot, followed by the result:</p>
<p>“Give me a poem using PIBO and the important work it does as the subject.” It took ten seconds. “And now&thinsp;.&thinsp;.&thinsp;.&thinsp;including mosquitoes, chiggers, stable flies and mud”:</p>
<div style="margin-left: 4.5em;">
Upon Pelee Island, where the migrators roam,<br />
There exists a sanctuary, a cherished home.<br />
PIBO stands strong, in this nature’s canvas,<br />
Guarding avian secrets, amidst the wilderness vast. </p>
<p>Dawn lights up the skies, warblers sing their tune,<br />
While mosquitoes buzz and chiggers commune.<br />
Stable flies flutter, adding to the whirl,<br />
In this muddy haven, life’s mysteries unfurl. </p>
<p>With gentle hands, they band and observe,<br />
Each bird, each flight path, each graceful curve.<br />
Their research, a beacon through the migration night,<br />
Guiding safely, each feathered flight.</p>
<p>Tales of epic journeys, of tempests braved,<br />
By our avian kin, by PIBO saved.<br />
And amidst the insects’ dance and the fertile mud,<br />
Echoes the rhythm of life’s ceaseless flood.</p>
<p>Through the digital window, the world looks on,<br />
As PIBO’s mission is daily drawn.<br />
From this mud-rich base, to lands afar,<br />
Spread the lessons of life, each under a star.</p>
<p>Thus stands PIBO, on Pelee’s serene coast,<br />
A sentinel of the skies, humanity’s boast.<br />
Among mosquitoes, chiggers, and stable flies’ hum,<br />
Sings the profound mission, of the noble PIBO’s drum.</p></div>
<p>You see what I mean about the punctuation? I might note as well that Pelee Island is not exactly a “wilderness vast”—see map, a thing the chatbot evidently did not do—and that the idea of chiggers communing in your armpits, though whimsical, is not observant of their social habits, which are nul. Nor do stable flies flutter, unless by happy chance you’ve smacked one of them and it’s not dead yet. </p>
<p>Yes, I know. You’ll say that these are minor quibbles, and your Uncle Roger writes doggerel verse like this by the yard and sends it out to you every Christmas. I point out that a chatbot replacing Uncle Roger might very well happen, but, dear published author, it is not yet very likely to replace you.</p>
<p>My second demonstration piece was instigated by The Walrus. Here is the ask, followed by the response:</p>
<p>Prompt: Can you write a dark and dystopian short story in the voice of Margaret Atwood that takes place in Canada?</p>
<div style="margin-left: 4.5em;"><strong>The Weeping Willows of Winnipeg</strong></p>
<p>Every morning, as the rose-tinted dawn slices the stillness of night, I see the Weeping Willows of Winnipeg. They stand tall yet humbled, their drooping branches laden with the invisible weight of despair. The people here, they too carry an unseen burden. Their weary faces are etched with deep lines, their eyes holding echoes of stories they’re too afraid to tell.</p>
<p>Winnipeg, once a thriving city, is now a desolate ghost town, crippled by the icy grip of the Northern Wastes that have extended their deadly reach. The permafrost that used to recede with the summer sun, now remains a permanent fixture, a chilling symbol of the loss we have borne.</p>
<p>The world changed after the Last Oil Crisis. Our dependence on fossil fuels had been our downfall. Nature, which we had exploited for centuries, took its revenge. Global warming accelerated, the Arctic ice caps melted and the Jet Stream collapsed, plunging Canada into a never-ending winter.</p>
<p>People adapted as best they could. We learned to survive in constant sub-zero temperatures, to huddle together for warmth, to forage for whatever we could eat. We learned to fear the silence, the vast, white stillness that swallowed the sounds of life. We learned to mourn the loss of the sun, the loss of hope.</p>
<p>The government, which we thought was a sturdy lighthouse guiding us through tumultuous waves, collapsed under the weight of its lies and deceit. Anarchy ensued. Gangs roamed the icy streets of Winnipeg, their eyes hollow, hearts even more so. Survival was the only law that mattered now.</p>
<p>I remember the days of warmth, the days of green trees, and blooming flowers. I remember the bubbling laughter of children, the bustling city streets, and the sweet scent of the bakery near our old house. Now, all that remains is the biting chill, the gnawing hunger, and the pervasive fear.</p>
<p>But the Weeping Willows, they keep me going. These ancient trees, they are the last vestige of the world that was. Their slender, weeping branches whisper tales of past springs and hopeful summers. They symbolize resilience, endurance. They are a beacon of hope in a world dominated by despair.</p>
<p>In their quiet lament, I hear a promise. A promise that nature will endure, that it will bounce back, reclaim its rightful place. Every morning, as I watch the dawn illuminate their snow-laden branches, I see a spark of life, a glimpse of the world that once was, and could be again.</p>
<p>The Weeping Willows of Winnipeg stand tall, not in defiance, but in acceptance of the harsh reality, and yet with a quiet assurance of a spring that may return. We must weather this winter of our discontent, like the willows, bending but never breaking. After all, hope is a stubborn thing; it survives even in the darkest of times, it thrives in the coldest of hearts.</p></div>
<p>When you return from the bathroom, having recovered from your bout of faux norovirus, give yourself a pat on the back. You, dear author, would never write anything so gawd-awful, and neither&mdash;unless my brain leaves for another planet&mdash;would I. Of course, some of you will make waggish jokes, such as “Sounds like Margaret Atwood to me,” and yes, maybe the bot is onto something with the weary-faced Winnipeggers and their secret stories of terror, no doubt concerning Pierre Poilievre.</p>
<p>But apart from that, gimme a break! If it’s a desolate, perma-frosted ghost town, why haven’t those folks just, you know, moved? And it got cold, but the sun is no longer shining? Really? </p>
<p>As for the weird title, the bot was evidently fed my alliterative children’s stories, such as <em>Princess Prunella and the Purple Peanut</em>. It mixes modes, and cannot seem to distinguish between kid’s lit and the grown-up stuff. Ask it to write a children’s story by Anaïs Nin and see what you get. </p>
<p>So sleep well tonight, dear authors. Your vocation is safe from the pod people. At least for now.</p>
<p><em>The fee for this article has been donated to PIBO, in honour of the partying chiggers and the fluttering stable flies that plague the bird banders. It will buy them some coffee. Since they get up at 5 a.m. to wade through the mud, they always need it. </em></p>The post <a href="https://thewalrus.ca/margaret-atwood-ai/">Margaret Atwood Reviews a “Margaret Atwood” Story by AI</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
		<item>
		<title>How ChatGPT Is Putting College Ghostwriters Out of Work</title>
		<link>https://thewalrus.ca/chatgpt-ghost-writers/</link>
		
		<dc:creator><![CDATA[Katrya Bolger]]></dc:creator>
		<pubDate>Wed, 27 Sep 2023 10:30:48 +0000</pubDate>
				<category><![CDATA[Technology]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[audio]]></category>
		<category><![CDATA[homepage]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=158698</guid>

		`

		<description><![CDATA[The custom essay-writing business is worth billions. Will AI bring it to an end?]]></description>
		<content:encoded><![CDATA[<img width="1600" height="1067" src="https://walrus-assets.s3.amazonaws.com/img/Bolger_ChatGPTEssays_1800_03-1.jpg" class="webfeedsFeaturedVisual wp-post-image" alt="A photo illustration of an essay paragraph where the words are a blend of Times New Roman font and binary code." loading="lazy" style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/Bolger_ChatGPTEssays_1800_03-1.jpg 1600w, https://walrus-assets.s3.amazonaws.com/img/Bolger_ChatGPTEssays_1800_03-1-735x490.jpg 735w, https://walrus-assets.s3.amazonaws.com/img/Bolger_ChatGPTEssays_1800_03-1-1536x1024.jpg 1536w, https://walrus-assets.s3.amazonaws.com/img/Bolger_ChatGPTEssays_1800_03-1-1200x800.jpg 1200w, https://walrus-assets.s3.amazonaws.com/img/Bolger_ChatGPTEssays_1800_03-1-348x232.jpg 348w" sizes="(max-width: 1600px) 100vw, 1600px" /><p><span class="dropcap">I</span><span class="smallcaps">n 2012,</span> Bruce Ross posted an online advertisement offering to help students write their academic papers. The Vancouver-born journalist was working at a local newspaper in small-town British Columbia and seeking a way to supplement his modest income. For $20 per page, Ross wrote in his post, he would pen a paper on any topic for students struggling to meet their deadlines. It wasn’t long before he picked up a steady stream of customers. Within six months, Ross (not his actual name) was making over double, as a ghostwriter, of what he was earning in his day job as a reporter. About one year later, he handed in his resignation to the newspaper and moved to Costa Rica to focus on his growing clientele of students.</p>
<p>The product of that move was <a href="https://www.myessaywriter.net/" rel="noopener" target="_blank">My Essay Writer</a>, a website that promises students high grades and a fast turnaround. Today, Ross, now based in Miami, oversees a team of twenty full-time writers who crank out dozens of essays for clients per week, including post-secondary and high school students from around the world. He estimates about 10 percent of his clientele comes from Canada.</p>
<ul class="related">
<li><a href="https://thewalrus.ca/wait-is-chatgpt-even-legal/">Wait—Is ChatGPT Even Legal?</a></li>
<li><a href="https://thewalrus.ca/will-ai-actually-mean-well-be-able-to-work-less/">Will AI Actually Mean We’ll Be Able to Work Less?</a></li>
<li><a href="https://thewalrus.ca/ai-poetry/">Robots Are Writing Poetry, and Many People Can’t Tell the Difference</a></li>
</ul>
<p>Paying third parties to complete your coursework is called contract cheating. While it seemingly represents a breach of academic integrity, it is technically legal in Canada&mdash;and data suggests it’s become prevalent across post-secondary institutions. According to academic ghostwriters like Ross, their work is fair game in a world where post-secondary institutions are failing their students with false promises of prestige following the completion of their degrees. “Colleges are basically businesses,” he says. “People look at what we do as a ‘no-no’ in a moral sense, but they don’t really question the ethics of what the school system is doing to a lot of the students, making these promises to them.” Amid reports of growing financial pressures and mental health challenges, these services have become a lifeline for some, says Ross. A line on his website echoes this sentiment: “You shouldn’t be spending your best years stressed out over assignments that have nothing to do with your career goals.”</p>
<p>Ross’s business, however, is facing a threat: artificial intelligence. Since ChatGPT launched last year, the popular chatbot has opened up a convenient new pathway for students who need to submit essays, while bringing the issue of cheating into sharper focus for schools. For decades, custom essay-writing services have gone largely unchallenged&mdash;but could ChatGPT and tougher anti-cheating measures finally put them in peril?</p>
<p><span class="dropcap">S</span><span class="smallcaps">tatistics on the scope</span> of the contract-cheating industry in Canada are sparse, but the global market for custom essay-writing companies is estimated to be worth up to $21 billion (US). A 2006 study by the University of Central England suggested that Canada was among the top four countries where students engage in contract cheating. <a href="https://ucalgary.ca/news/cheating-may-be-under-reported-across-canadas-universities-and-colleges" rel="noopener" target="_blank">A more recent study</a>, from January 2020, estimates that over 70,000 post-secondary students in Canada were likely taking part in contract cheating at least once per year. That represents about 3.5 percent of the country’s post-secondary students.</p>
<p>Reliance on these services appears to have worsened during the pandemic as learning went online. A study by Alberta-based MacEwan University found that, during 2019/20, contract cheating increased nearly tenfold, due, at least in part, to the impact of the pandemic on students. These incidents are also taking place against a broader rise in academic-integrity breaches aided by technology such as ChatGPT.</p>
<p>The custom essay-writing industry can be traced as far back as the 1930s. Student newspapers, such as the <em>Varsity</em> of the University of Toronto, first posted advertisements for custom essays in the 1960s. In fact, seeing these advertisements on Canadian campuses was, until recently, quite common. Early attempts to stop the industry went nowhere. In April 1972, the Ontario legislature floated the idea of passing a new law to stop companies from helping students cheat. However, the proposed legislation failed to make it past first reading. In 1989, the Ontario court brought a landmark case against Custom Essay Service, an essay company that had been operating since the 1970s. The company was charged with one count of conspiracy to utter forged documents and seven counts of creating them. The case was eventually dismissed&mdash;but not before over 100 students faced disciplinary charges for purchasing papers from the company.</p>
<p>Experience has shown that students can pay a steep price for relying on these writing services, up to and including having their credentials withdrawn by their universities. Some students have also been blackmailed by the contract-cheating companies after they tried to cancel their payments.</p>
<p>Sarah Elaine Eaton, an associate professor at the University of Calgary’s Werklund School of Education, has been sounding the alarm over contract cheating in Canada for years. Since 2018, she has been working with teams across the country to establish anti–contract cheating measures in post-secondary institutions. A key part of that has entailed trying to get contract cheating incorporated within the definitions of academic misconduct at colleges and universities. However, Toronto Metropolitan University and MacEwan University are currently among the few post-secondary institutions that clearly incorporate contract cheating in their academic-integrity policies. This has implications for how the trend is actively tracked, says Eaton: “If universities aren’t recognizing contract cheating, or they’re subsuming it under plagiarism or collusion, then we’re not getting any data about the rates that are happening on our campuses, because they’re getting classified in inappropriate ways. You can’t solve a problem if you don’t name the problem.”</p>
<p>Even with such policies in place, detecting contract cheating can be tricky. Turnitin, the plagiarism-prevention software, is already used in Canadian universities and colleges to assess similarities to existing texts. But the software requires several writing samples from the student in question to accurately assess the authorship of the text, and it has been criticized for its low level of accuracy. It’s often up to the class instructors, or markers, to flag cases of cheating based on their assessment of the patterns in the tone, substance, or grammar in a student’s work.</p>
<p>According to Eaton, when it comes to government action on contract cheating, Canada has a long way to go compared to its counterparts in the Western world. In recent years, England and Australia have played leading roles in cracking down on cheating services. In 2020, for example, Australia passed a law making it a criminal offence to provide such services. And in 2022, the English government followed suit by outlawing any advertisements for them. Eaton attributes these countries’ success to the national quality-assurance bodies within their higher education systems that have led anti–contract cheating reforms, which have been supported by their governments. In Canada, education policies are provincial or regional responsibilities, and by and large, according to Eaton, these “quality assurance bodies have not paid much attention to contract cheating at all.”  </p>
<p>While there are no large-scale legislative efforts to tackle contract cheating in Canada, there are some specific initiatives aimed at bringing the issue to the attention of decision makers. In 2018, the Academic Integrity Council of Ontario created a sub-committee to reduce contract cheating in that province’s post-secondary institutions. That led to awareness initiatives, prevention strategies, and an articulation of clearer policies and procedures. And following the inaugural Canadian Symposium on Academic Integrity, held in Calgary in 2019, three similar networks were established, in Alberta, Manitoba, and British Columbia, to do the same.</p>
<p>Academic-integrity experts say awareness is key to pushing their agenda. However, Eaton suggests that post-secondary institutions are often reluctant to talk about the reality of contract cheating. At the University of Calgary, where she works, she says, she still finds advertisements for “Write my essay” around campus. “We’re still very much at the place [where] schools don’t want to air their dirty laundry, they don’t want to talk about taboo topics. And I think the way to address it is for schools to get together and the provincial councils to get together, acknowledge that it happens, and then work to find solutions.”</p>
<p><span class="dropcap">W</span><span class="smallcaps">hy are students</span> drawn to cheating in this form? According to those who work closely on these issues, several factors are at play. Amanda McKenzie, who leads the Academic Integrity Office at the University of Waterloo, says students struggling with the pressure to perform, coupled with poor time-management and organizational skills, often turn to these services: “When students get into a time crunch and get into a corner, they rationalize they can do anything that they can to maintain their work or hand it in even if they have to engage in misconduct to achieve it.”</p>
<p>She also attributes this to the commodification of education&mdash;the idea of a degree as an economic stepping stone as opposed to a means for learning and social or personal development. Over time, McKenzie says, post-secondary institutions have tended to emphasize performance, grades, and outcomes instead of learning and processes. When students feel disconnected from the process of learning, as many clearly did during the pandemic, she says, they are only more likely to engage in cheating.</p>
<p>Scholars have further suggested that systemic challenges in the academic world are shaping the growth of the contract-cheating industry. On the teaching side, work assignments can be precarious and larger class sizes can create more impersonal experiences. This almost inevitably trickles into the student experience, including a sense of dissatisfaction, which, according to at least one study, may increase the chances of students turning to contract cheating.</p>
<p>For his part, Ross says there is no one type of student that is drawn to his services. What they share in common is simply the fact that they are stressed. “[Schools] are telling students they can take a program, graduate, and get a job. And what they really end up with is $50,000 in debt and no job.” Cheating, he says, is often a last resort to simply get by.</p>
<p>Ross acknowledges that AI tools such as ChatGPT could be a threat to his work, noting he has seen a slight drop in demand in recent months. While a slew of other factors could be behind this, the popularity of the chatbot is hard to ignore. A study published by Academica Group early this year found that 43 percent of the 626 post-secondary students surveyed reported having used the AI-powered tool for their school assignments. However, only 4 percent of those queried said they used it to “write” a whole assignment.</p>
<p>In anticipation of these changes, Ross is already diversifying his business. For example, he’s hoping to launch a tutoring division to help students approach their assignments more effectively rather than simply producing papers for them. </p>
<p>Part of his business strategy is also letting his clients know that his team is made up of “human writers, not robots”&mdash;something he believes helps him stay competitive. When it comes to using ChatGPT, Ross says, he has no plans to use it in his own work “because schools have tools to detect AI.” And as these detection tools become more sophisticated, he says, he could actually see students increasingly turning to custom essay-writing services to avoid getting caught. He adds that he has no interest in getting students into trouble: “We had the option in the past to reuse papers we had already written, but we never did that since Turnitin would see it and the client would fail.” That means they would have to refund the clients and lose referrals and repeat orders; in other words, it would be bad for business. </p>
<p>Ross’s website currently has no section that explicitly warns students of the consequences of submitting work that they did not write themselves, such as getting expelled if they are caught.      Ross says students are encouraged to use his company’s work as samples to guide their own writing (though it’s clear from the site that they also expect you to simply hand in the essays they write). </p>
<p>When asked if he would have used cheating services himself when he was a student, Ross says he would have&mdash;if he had the money. He describes himself as a rebellious teenager until he got into a car accident when he was twenty-one. That forced him to take his educational goals seriously. “I went from one teacher in my first year failing my essay and telling me she thought I was an ESL student to winning second place in a provincial newspaper-writing contest four years later,” he says. And while Ross won that writing contest fair and square, he still believes that his clients, often struggling toward their own goals, should have the opportunity to do the same by whatever means it takes.</p>The post <a href="https://thewalrus.ca/chatgpt-ghost-writers/">How ChatGPT Is Putting College Ghostwriters Out of Work</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
		<item>
		<title>The Novel Written about&#8212;and with&#8212;Artificial Intelligence</title>
		<link>https://thewalrus.ca/the-novel-written-about-and-with-artificial-intelligence/</link>
		
		<dc:creator><![CDATA[Brian Bethune]]></dc:creator>
		<pubDate>Thu, 07 Sep 2023 10:30:54 +0000</pubDate>
				<category><![CDATA[Books]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[audio]]></category>
		<category><![CDATA[Canadian Fiction]]></category>
		<category><![CDATA[canadian literature]]></category>
		<category><![CDATA[homepage]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=157930</guid>

		`

		<description><![CDATA[<em>Do You Remember Being Born?</em>&thinsp; is a tech-inflected novel for a digital world]]></description>
		<content:encoded><![CDATA[<img width="1600" height="1067" src="https://walrus-assets.s3.amazonaws.com/img/Bethune_SeanMichaels_FallBooks2023_1800.jpg" class="webfeedsFeaturedVisual wp-post-image" alt="A photo illustration of a person’s eye getting scanned." loading="lazy" style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/Bethune_SeanMichaels_FallBooks2023_1800.jpg 1600w, https://walrus-assets.s3.amazonaws.com/img/Bethune_SeanMichaels_FallBooks2023_1800-735x490.jpg 735w, https://walrus-assets.s3.amazonaws.com/img/Bethune_SeanMichaels_FallBooks2023_1800-1536x1024.jpg 1536w, https://walrus-assets.s3.amazonaws.com/img/Bethune_SeanMichaels_FallBooks2023_1800-1200x800.jpg 1200w, https://walrus-assets.s3.amazonaws.com/img/Bethune_SeanMichaels_FallBooks2023_1800-348x232.jpg 348w" sizes="(max-width: 1600px) 100vw, 1600px" /><p><span class="dropcap">T</span><span class="smallcaps">hree distinct</span> personalities, all female, walk into a bar together in <em>Do You Remember Being Born?</em>&thinsp; and emerge with fat paycheques, a collaborative long poem slyly titled “Self-portrait,” and a lot of nagging doubt. Actually, the proverbial bar in Sean Michaels’s dizzying new novel is not a bar but the Mind Studio, an entry-by-key-card-and-retina-scan-only room on an unnamed tech giant’s San Francisco campus. And one of the three personalities, a “2.5-trillion-parameter neural network” named Charlotte, is better described as feminine than female. But the doubt, tucked under a lot of surface-level optimism, is real, instilled in characters and readers alike by the author.</p>
<p>Small wonder Michaels is among the “digital-savvy slate of authors”&mdash;indeed, the only one mentioned by name in a <em>Publishers Weekly</em> <a href="https://www.publishersweekly.com/pw/by-topic/industry-news/trade-shows-events/article/92954-markus-dohle-ethan-mollick-to-keynote-ai-webinar.html" rel="noopener" target="_blank">press release</a>&mdash;set to take part in a late-September publishing-industry webinar about <a href="https://thewalrus.ca/tag/artificial-intelligence/" rel="noopener" target="_blank">AI</a>’s expected impact. Before writing <em>Do You Remember</em>, the Montreal author and critic co-designed Moorebot, a piece of poetry-generation software animated by a literary corpus that includes the collected works of the celebrated American poet Marianne Moore (1887–1972) and an entire anthology of twenty-first-century Canadian <a href="https://thewalrus.ca/category/poetry/" rel="noopener" target="_blank">poetry</a>. Moorebot, in conjunction with OpenAI’s GPT-3 language model, is an essential co-author in Michaels’s collaborative novel about human–AI poetry collaboration: all the poetry contributed by Charlotte and some of the prose (indicated on the page by grey shading) were generated with its help. </p>
<p>There is far less of the prose than of the poetry, but its effect is more unsettling. When Michaels inserts the shaded words “A swath of solid white&mdash;a moonbeam frozen in place, like a streak of static,” he clearly likes the choice and rhythm of the words. What is less clear is whether he intended one insistent effect: it is a lovely image, yes, but was the desire to display it the primary reason why Michaels’s story, which had unfolded in daylight hours, now has an evening scene? Are readers being nudged to look behind the curtain of artistic creativity and to question their own assumptions about what really distinguishes humans from machines? </p>
<p><a href="https://thewalrus.ca/fall-books/" rel="noopener" target="_blank"><img loading="lazy" src="https://walrus-assets.s3.amazonaws.com/img/FallBooks_2023_ReadMore_970x250.jpg" alt="" width="970" height="250" class="alignnone size-full wp-image-141896" /></a></p>
<p>That’s merely one of numerous subtle chords plucked throughout the novel. Michaels’s main protagonist, seventy-five-year-old poet Marian Ffarmer, is not based on Moore&mdash;she <em>is</em> Moore, although the real-life poet never existed in Ffarmer’s world. She wears Moore’s signature tricorn hat and black cape without any reference to a predecessor, and she utters Moore verses as if they were her own. Both poets receive a call from one of their era’s economic titans. In 1955, Moore was asked to suggest inspirational names for a new Ford car and came up with such gems as Utopian Turtletop for the model eventually christened the Edsel, one of the great failures in auto history. The contemporary tech company wants Ffarmer to show the world, via fruitful collaboration, what their Charlotte is capable of. </p>
<p>Ffarmer, far from affluent, doesn’t hesitate to accept the proffered $80,000 commission. She understands&mdash;and shares to an uncertain degree&mdash;the fears AI has inspired among writers and other creators. As Ffarmer caustically comments, the company wants her collaborative poem as “a memorial for a bygone age, back when only <em>people</em> wrote poems, before my kind had gone the way of lamplighters and travel agents, icemen, video store clerks.” But she desperately wants the money, to give it to her only child, the son she feels she often neglected for her artistic calling. Childbirth, children, and childlessness are as central to the novel as its title signals. Moore was unmarried and childless; so, too (of course), is Charlotte, and she asks Ffarmer, “Do you remember being born?” because she herself is the only one who can answer, “Yes.” </p>
<p>At first, the poet is impressed with Charlotte’s vast “left field”&mdash;the store of imagery, ideas, metres, and rhythms provided by the millions of English-language poems fed to her&mdash;from which she can instantly craft continuations of Ffarmer’s lines. Then she’s dismissive, as she judges Charlotte’s offerings to be attractive but meaningless word associations. Then she is silenced, upon learning that when her poems were programmed into Charlotte, they came with the instruction, the network says, “to let them have a much more important impact on me than the average”&mdash;just one aspect of the tech firm stacking the deck for a successful outcome. The implications shock Ffarmer. Consider the audience, she muses, the pattern-seeking human species and its capacity to take meaning from anything, however hollow. Did she initially warm to Charlotte’s empty contributions because she was seduced by her own voice, she wonders, and was that a career-long tendency she had never noticed? “I wondered how much of what I had published in my life was a deception.”</p>
<p>But despite the company’s various manipulations and Ffarmer’s drive to cooperate, their grand collaboration begins to flail. Enter the third voice: a young, truculent, starving-in-a-garret poet Ffarmer meets by happy accident. For the older poet, Morel Ferarri is the force of nature Ffarmer hopes can soothe her doubts and bind her to her AI mirror. For all <em>Do You Remember Being Born?</em>&thinsp;’s sweeping consideration of the implications of AI’s arrival on the creative scene, this stunningly compelling novel turns on a far more random arrival: in human affairs, contingency still rules.</p>The post <a href="https://thewalrus.ca/the-novel-written-about-and-with-artificial-intelligence/">The Novel Written about—and with—Artificial Intelligence</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
		<item>
		<title>Better AI for a Better Society</title>
		<link>https://thewalrus.ca/better-ai-for-a-better-society/</link>
		
		<dc:creator><![CDATA[Elizabeth Chorney-Booth]]></dc:creator>
		<pubDate>Wed, 06 Sep 2023 15:25:51 +0000</pubDate>
				<category><![CDATA[Paid Post]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[Google]]></category>
		<category><![CDATA[hide-ads]]></category>
		<category><![CDATA[no-ads]]></category>
		<category><![CDATA[no-newsletter]]></category>
		<category><![CDATA[Technology]]></category>
		<category><![CDATA[The Walrus Lab]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=157860</guid>

		`

		<description><![CDATA[Canadian researchers are developing AI tech to help build a better world]]></description>
		<content:encoded><![CDATA[<img width="1600" height="799" src="https://walrus-assets.s3.amazonaws.com/img/Header_GoogleAi_1200px-2.png" class="webfeedsFeaturedVisual wp-post-image" alt="Header_GoogleAi" loading="lazy" style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/Header_GoogleAi_1200px-2.png 1600w, https://walrus-assets.s3.amazonaws.com/img/Header_GoogleAi_1200px-2-1536x767.png 1536w, https://walrus-assets.s3.amazonaws.com/img/Header_GoogleAi_1200px-2-2048x1023.png 2048w" sizes="(max-width: 1600px) 100vw, 1600px" /><style> .gallery {/*margin-bottom: 0; top: -40px; position: relative;*/}
div.gallery span.hm-tagged {/*  margin: 0; */}
</style>
<p><span class="dropcap" ;="" style="color: #c22026; font-family: Inconsolata; font-weight: Bold;">N</span><span class="smallcaps">o topic in 2023</span>  has captured the public’s attention like artificial intelligence (AI) and machine learning models. With large language models (LLMs) and AI art generators now widely available, Canadians are equally intrigued and concerned by the possibilities. As with any new technology, this anxiety is natural. But when appropriately developed, AI can be a game-changer in improving how we live, work, and play. </p>
<div class="su-row"></div><div class="su-column su-column-size-1-5 su-pullquote su-pullquote-align-left"><div class="su-column-inner su-u-clearfix su-u-trim">
<p style="margin-bottom: 0px; text-align: center;"><img loading="lazy" src="https://walrus-assets.s3.amazonaws.com/img/Shek.png" alt="Shek Azizi Portrait" width="187.5" height="187.5" class="size-full wp-image-139538" /></p>
<p style="font-family: Inconsolata; color: #8e8d8d; text-align: center; padding-bottom: 10px; line-height: 1.2; font-size: .9rem;"><b style="color: #c22026;">Shek Azizi,<br /> </b> Senior Research Scientist; Google DeepMind</p>
<p style="margin-bottom: 0px; text-align: center;"><img loading="lazy" src="https://walrus-assets.s3.amazonaws.com/img/Vincent.png" alt="Vincent Dumoulin Portrait" width="187.5" height="187.5" class="size-full wp-image-139538" /></p>
<p style="font-family: Inconsolata; color: #8e8d8d; text-align: center; padding-bottom: 5px; line-height: 1.2; font-size: .9rem;"><b style="color: #c22026;">Vincent Dumoulin,<br /> </b> Senior Research Scientist; Google DeepMind</p>
</div></div> </p>
<div class="su-column su-column-size-4-5"><div class="su-column-inner su-u-clearfix su-u-trim"> Without even thinking about it, most of us already use some form of AI every day. The face recognition that unlocks our phones, digital map navigation, word suggestions on texting platforms, and personalized recommendations on streaming services all employ some degree of artificial intelligence, which users happily accept since it makes day-to-day life easier. AI has the potential to unlock scientific discoveries, and tackle humanity’s greatest challenges and opportunities. At the same time, it is still an emerging technology and needs to be developed responsibly.</p>
<p>Canada is uniquely positioned to be leading the way in AI innovation, thanks to its strong academic institutions, rich local talent, startups, and research facilities like Mila in Montreal or Toronto’s Vector Institute. Companies at the forefront of this AI shift, like Google, have long recognized Canada as a place to invest. Google employs many forward-thinking research scientists, particularly through laboratories like Google DeepMind which has teams in Montreal and Toronto. Such labs allow Canadian researchers to dig deeply into the potential of AI by addressing some of society’s biggest challenges.</p>
<div class="su-spacer" style="height:15px"></div>
<p style="font-family: Inconsolata; font-size: 160%; color: #c22026; font-weight: bold; margin-bottom: 10px; text-transform: uppercase; letter-spacing: 1px;">Revolutionizing medicine</p>
<p> One of the most exciting innovations to emerge from Google DeepMind is Med-PaLM, a LLM designed to provide high-quality answers to medical questions. LLMs are programs trained to understand and answer questions in a human-like manner, such as ChatGPT and Google’s Bard. Tech companies have been working on building LLMs to answer medical questions for years. But complications from collecting data, employing medical-specific vocabulary, and accuracy—which could be harmful or even fatal in the medical realm—have caused significant challenges for researchers. </p>
<p>Med-PaLM has proven to be a real breakthrough in this area. Shek Azizi, senior research scientist at Google DeepMind, and her team use the US Medical License Exam (USMLE) style questions as a tool to measure Med-PaLM’s effectiveness. Google’s first version of Med-PaLM, completed in December 2022, was the first AI system to obtain a passing score (over 60 percent) on these questions. This model not only answered multiple choice and open-ended questions accurately, but also provided rationale and evaluated its own responses. The next iteration, Med-PaLM 2, consistently performed at an “expert” doctor level on medical exam questions, scoring 85 percent. “MedPaLM is designed to provide accurate and alternative answers to medical questions,” Azizi says. “This tech can accelerate the translation of AI solutions and have a clinical impact in a safe and responsible way to improve the lives of billions of people.”</p>
<p>Don’t expect a Med-PaLM-enabled robot to replace your GP. Doctors will likely use Med-PaLM to summarize their notes more efficiently or double-check diagnoses, providing much-needed efficiency as Canada continues to experience a shortage of physicians with many health care professionals feeling overworked and burnout.</p>
<p>“The models can augment the work of professionals in this space,” Azizi says. “They can be used to improve the clinical workflow in a way that gives humans more time to advance things that matter and provide patient care instead of spending time on tasks that can be automated through AI systems.”</p>
<div class="su-spacer" style="height:15px"></div>
<p style="font-family: Inconsolata; font-size: 160%; color: #c22026; font-weight: bold; margin-bottom: 10px; text-transform: uppercase; letter-spacing: 1px;">Revolutionizing conservation</p>
<p> While streamlining health care systems feels like a natural application for AI, scientists can also use these technologies to solve a wide range of societal issues—some you might not expect. Canadian Google DeepMind research scientist, Vincent Dumoulin, and his team are working on a project called Perch, which uses bioacoustics technology to identify bird songs in audio files. When an audio clip is fed through Perch, the technology identifies the location of the bird species where the clip was recorded. This, in turn, can be used to protect endangered species or to get a better picture of a region’s bird population.</p>
<div class="su-divider su-divider-style-default width=100%" style="margin:15px 0;border-width:3px;border-color:#c22026"></div>
<div class="su-spacer" style="height:10px"></div>
<p style="font-family: Inconsolata; font-size: 150%; color: #c22026; font-weight: bold; text-align: center; margin-bottom: 10px; letter-spacing: 1px;">“We need to develop AI systems in a way that maximizes the positive benefit to society.”</p>
<p style="text-align: center; font-family: Inconsolata; font-weight: 100;">Shek Azizi</p>
<div class="su-divider su-divider-style-default width=100%" style="margin:15px 0;border-width:3px;border-color:#c22026"></div>
<p>The function may seem simple, but the science behind training AI to identify bird songs, many of which might not be in the foreground of the recording, is very complex.</p>
<p>“We will feel that we have succeeded if a conservationist can take these models and repurpose them for a problem we hadn’t even anticipated,” Dumoulin says. “Our philosophy is not necessarily to go out into the world and deploy those models directly, but to provide tools that will allow conservationists to effect change.”</p>
<p>Both Azizi and Dumoulin are clear about that role: organizations like Google act to enable humans with tools that facilitate the work of making the world a better place, be it through medical advancements, environmental protection, or simply granting humans more leisure time. That said, both scientists and Google recognize the need to consider ethical responsibilities in any research and product development.
</p>
<div class="su-spacer" style="height:15px"></div>
<p style="font-family: Inconsolata; font-size: 160%; color: #c22026; font-weight: bold; margin-bottom: 10px; text-transform: uppercase; letter-spacing: 1px;">Maintaining ethics</p>
<p> For a technology like Med-PaLM, those responsibilities extend to ensuring accuracy, and addressing privacy concerns and biases in the collection of medical data used to train the LLM. Responsibility is a guiding principle in all of Google’s AI work, which is why the company developed AI principles in 2018. The principles are a set of concrete standards that will actively govern their research and product development, and impact their business decisions.</p>
<p>“It is crucial for society and community to practise AI responsibly,” Azizi says. “We need to develop AI systems in a way that maximizes the positive benefit to society while also being aware of the challenges and addressing them actively.”</p>
<p>Dumoulin agrees. While he believes in the immense positive potential of AI, he’s also careful to diffuse the public’s tendency towards anthropomorphizing it or imagining the technology as a human brain making decisions. It is, rather, a series of programs and applications designed by humans to address specific tasks. People are guiding the AI, not the other way around. Like any other tool, from the automobile to the invention of the internet, it’s our duty to use this technology for good.</p>
<p>“With these innovations, it’s up to us collectively to make sure the benefits are distributed to everyone,” Dumoulin says. “That’s something that transcends AI and machine learning.”</p>
<div class="su-divider su-divider-style-default width=100%" style="margin:15px 0;border-width:3px;border-color:#c22026"></div>
<p><strong>FOR MORE INFORMATION ABOUT GOOGLE’S WORK WITH AI, VISIT <u><a href="http://AI.GOOGLE">AI.GOOGLE</a></u>.</strong></p>
</div></div>The post <a href="https://thewalrus.ca/better-ai-for-a-better-society/">Better AI for a Better Society</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
		<item>
		<title>Wait&#8212;Is ChatGPT Even Legal?</title>
		<link>https://thewalrus.ca/wait-is-chatgpt-even-legal/</link>
		
		<dc:creator><![CDATA[Fenwick Mckelvey]]></dc:creator>
		<pubDate>Mon, 28 Aug 2023 10:30:18 +0000</pubDate>
				<category><![CDATA[Technology]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[audio]]></category>
		<category><![CDATA[homepage]]></category>
		<category><![CDATA[law]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=157575</guid>

		`

		<description><![CDATA[AI companies are using copyrighted works to train their systems. The lawsuits are just getting started]]></description>
		<content:encoded><![CDATA[<img width="1600" height="1067" src="https://walrus-assets.s3.amazonaws.com/img/McKelvey_AILaw_cg_1800.jpeg" class="webfeedsFeaturedVisual wp-post-image" alt="A photo illustration of a giant robotic hand tipping over one side of a scale of justice." loading="lazy" style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/McKelvey_AILaw_cg_1800.jpeg 1600w, https://walrus-assets.s3.amazonaws.com/img/McKelvey_AILaw_cg_1800-735x490.jpeg 735w, https://walrus-assets.s3.amazonaws.com/img/McKelvey_AILaw_cg_1800-1536x1024.jpeg 1536w, https://walrus-assets.s3.amazonaws.com/img/McKelvey_AILaw_cg_1800-1200x800.jpeg 1200w, https://walrus-assets.s3.amazonaws.com/img/McKelvey_AILaw_cg_1800-348x232.jpeg 348w" sizes="(max-width: 1600px) 100vw, 1600px" /><p><span class="dropcap">“M</span><span class="smallcaps">achines seek no</span> public policy purpose, and there is no public benefit in replacing artists with them as content creators.” <a href="https://www.wgc.ca/sites/default/files/2023-06/WGC%20Letter%20to%20PCH-ISED%20on%20AI_June%202023.pdf" rel="noopener" target="_blank">This warning</a> came in June, from the Writers Guild of Canada, which represents around 2,500 English-language screenwriters working across TV, film, digital media, and radio. In a letter to the ministers of heritage and innovation, science, and industry, the WGC insisted that the government play “a leading role” in protecting the economic interests of Canadian creators from the threat of generative <a href="https://thewalrus.ca/tag/artificial-intelligence/" rel="noopener" target="_blank">AI</a>. </p>
<p>Generative AI, of course, refers to that subset of artificial intelligence that can generate video, images, music, and text. It’s the technology behind the breakout hit ChatGPT, a tool that answers questions using natural, human-like language and can simulate writing styles. Thanks to its broad utility, generative AI promises to become foundational for new services and economies. The technology has also sparked controversy and legal challenges. Artists and creators have been the most vocal, but the debate is also drawing in other industries concerned with how automation will reshape society. </p>
<ul class="related">
<li><a href="https://thewalrus.ca/ai-is-coming-for-voice-actors-artists-everywhere-should-take-note/">AI Is Coming for Voice Actors. Artists Everywhere Should Take Note</a></li>
<li><a href="https://thewalrus.ca/will-ai-actually-mean-well-be-able-to-work-less/">Will AI Actually Mean We’ll Be Able to Work Less?</a></li>
<li><a href="https://thewalrus.ca/ai-poetry/">Robots Are Writing Poetry, and Many People Can’t Tell the Difference</a></li>
</ul>
<p>That concern is not simply about how generative AI threatens to erode, and overtake, human creativity. It goes deeper: Are such models legal? There isn’t an easy answer. Today’s AI systems are variations of machine learning that require a lot of data to train on (as well as a lot of energy-intensive processing). The more data they get, the more accurate the systems become. Where do AI teams find all that data? The internet. <a href="https://commoncrawl.org/" rel="noopener" target="_blank">Common Crawl</a>, the nonprofit which scrapes the entire internet every month or two and makes the archive available to researchers for free, released its latest data set this summer. It contains 3.1 billion web pages collected from 35 million registered domains and includes 1 billion new URLs. You would need over 750 512 GB iPhones to hold it all. </p>
<p>ChatGPT’s legal status depends on how it treats this public data. OpenAI, the Microsoft-backed company that created the advanced chatbot, promises not to “actively seek out personal information to train our models, and we do not use public information on the internet to build profiles about people, advertise to or target them, or to sell user data.” The problem is AI systems tend not to distinguish between what’s private and what isn’t. They gobble up whatever they find. But to process personal information, AI companies need explicit consent. In March, the Italian government was the first in the world to ask whether OpenAI had complied with regulations governing the protection of personal data. Citing the lack of clarity around the company’s practices, Italy <a href="https://www.theverge.com/2023/4/28/23702883/chatgpt-italy-ban-lifted-gpdp-data-protection-age-verification" rel="noopener" target="_blank">initially banned ChatGPT</a>. The ban, lifted after OpenAI agreed to a set of privacy controls, has turned into a larger investigation into the technology’s relationship to Europe’s data collection rules. </p>
<p>Now, Canada’s Office of the Privacy Commissioner and its provincial affiliates are <a href="https://www.priv.gc.ca/en/opc-news/news-and-announcements/2023/an_230525-2/" rel="noopener" target="_blank">asking a similar question</a>: Did ChatGPT process the personal information of Canadians without expressed consent? The answers to these concerns, and OpenAI’s response, will shape the extent to which generative AI tools can be built on public data protected by privacy laws.</p>
<p>Foundational models could be at odds with copyright law too. Normally, making a copy of copyrighted work carries legal and financial consequences. There are exemptions, however, such as fair dealing in Canada (or the similar concept of fair use in the United States). Fair dealing means that you can make a copy for “the purpose of research, private study, education, parody or satire.” Notice that copying data to train a commercial foundational model does not appear on the list.</p>
<p>But these AI companies are quickly learning that you can use copyright laws to justify mass data collection. When Innovation, Science and Economic Development Canada asked for opinions on revising copyright laws, many companies called for their work to be protected under the rubric of academic fair dealing. This request raises worries about the autonomy of academic research in an era of AI&mdash;but also whether many commercial firms are exploiting academic exemptions to produce generative models with commercial intent. If development happens under academic fair dealing, is it okay for companies to profit from the results? We are finding out. Google is being sued for <a href="https://www.linkedin.com/pulse/google-faces-anothercopyright-infringement-lawsuit-expanding/" rel="noopener" target="_blank">copyright infringement</a>. Sarah Silverman <a href="https://www.bbc.com/news/technology-66164228" rel="noopener" target="_blank">is suing</a> OpenAI and Meta. The cases are piling up. </p>
<p>Government action could settle the privacy and copyright issues. New policy directives could decide that there is nothing illegal about how generative AI processes personal information, or they could rule against organizations like the Writers Guild, deciding that training a foundational model does not violate copyright. New laws could greenlight the technology so long as the industry adopts strict safeguards, such as the <a href="https://ised-isde.canada.ca/site/innovation-better-canada/en/artificial-intelligence-and-data-act" rel="noopener" target="_blank">proposed Artificial Intelligence and Data Act</a>, which sets out financial penalties for applications that harm individuals. Or the technology could be blocked outright for privacy violations, much like Italy did. </p>
<p>The real struggle might not be between AI and artists, or even governments, but with large copyright holders. What happens when Disney gets tired of ChatGPT fan-fictioning its Star Wars universe? Either large models will avoid using content from firms powerful enough to protect their intellectual property or they will pay for it. Large social media sites have already started selling their users’ data to companies. The result would be an AI system shaped by the few big players powerful enough to pay for training a large model and a few big firms willing to sell out their users’ data.  </p>
<p>But the problems for large foundational models are not just about data. AI might not be simply processing personal information but our very habits. “When we think about how AI might change labor, we have to understand that what we’re really doing is teaching the machine how to replace us,” <a href="https://www.publicbooks.org/machine-learning-is-a-co-opting-machine/" rel="noopener" target="_blank">writes</a> AI researcher Solon Barocas. “And so, in many situations, often without realizing it, the work that we are doing is being co-opted in some sense by the companies that are able to then use that to train the model to perform the job that we once did.” The issues only become more vexing when models training off stock images directly compete with the stock image photographers. Getty Images has <a href="https://www.reuters.com/legal/getty-images-lawsuit-says-stability-ai-misused-photos-train-ai-2023-02-06/" rel="noopener" target="_blank">already sued</a> Stable Diffusion, an AI model that creates images, for using its licensed content. </p>
<p>We might be quick to call AI firms pirates, but what we’re really watching is the rise of new empires. If we take the metaphor of machine learning seriously, then generative AI models learn from our common knowledge and sell that knowledge back to us. Co-opting, copying, processing, replacing: ChatGPT’s legal status is a proxy for a debate that is bigger than individual copyright or personal information. How do we foster an AI culture that cares about the public culture that created it? </p>The post <a href="https://thewalrus.ca/wait-is-chatgpt-even-legal/">Wait—Is ChatGPT Even Legal?</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
		<item>
		<title>Should Computers Decide How Much Things Cost?</title>
		<link>https://thewalrus.ca/computers-decide-cost/</link>
		
		<dc:creator><![CDATA[Colin Horgan]]></dc:creator>
		<pubDate>Mon, 14 Aug 2023 10:30:21 +0000</pubDate>
				<category><![CDATA[Technology]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[audio]]></category>
		<category><![CDATA[homepage]]></category>
		<category><![CDATA[shopping]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=157305</guid>

		`

		<description><![CDATA[If you feel like you’re spending more online all the time, it might be because you are]]></description>
		<content:encoded><![CDATA[<img width="1600" height="1067" src="https://walrus-assets.s3.amazonaws.com/img/Horgan_AlgorithmicPricing_cg_1800.jpeg" class="webfeedsFeaturedVisual wp-post-image" alt="A photo illustration of a price tag with binary code in the background." loading="lazy" style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/Horgan_AlgorithmicPricing_cg_1800.jpeg 1600w, https://walrus-assets.s3.amazonaws.com/img/Horgan_AlgorithmicPricing_cg_1800-735x490.jpeg 735w, https://walrus-assets.s3.amazonaws.com/img/Horgan_AlgorithmicPricing_cg_1800-1536x1024.jpeg 1536w, https://walrus-assets.s3.amazonaws.com/img/Horgan_AlgorithmicPricing_cg_1800-1200x800.jpeg 1200w, https://walrus-assets.s3.amazonaws.com/img/Horgan_AlgorithmicPricing_cg_1800-348x232.jpeg 348w" sizes="(max-width: 1600px) 100vw, 1600px" /><p><span class="dropcap">I</span><span class="smallcaps">n the summer of 2012,</span> the <em><a href="https://www.wsj.com/articles/SB10001424052702304458604577488822667325882" rel="noopener" target="_blank">Wall Street Journal</a></em> reported that the travel booking website Orbitz had, in some cases, been suggesting to Apple users hotel rooms that cost more per night than those it was showing to Windows users. The company found that people who used Mac computers spent as much as 30 percent more a night on hotels. It was one of the first high-profile instances where the predictive capabilities of algorithms were shown to impact consumer-facing prices.</p>
<p>Since then, the pool of data available to corporations about each of us (the information we’ve either volunteered or that can be inferred from our web browsing and buying histories) has expanded significantly, helping companies build ever more precise purchaser profiles. Personalized pricing is now widespread, even if many consumers are only just realizing what it is. Recently, other algorithm-driven pricing models, like Uber’s surge or Ticketmaster’s dynamic pricing for concerts, <a href="https://completemusicupdate.com/article/ticketmaster-sued-in-canada-over-pricing-of-drake-tickets/" rel="noopener" target="_blank">have surprised users and fans</a>. In the past few months, dynamic pricing&mdash;which is based on factors such as quantity&mdash;has pushed up prices of some concert tickets even before they hit the resale market, including for artists like Drake and Taylor Swift. And while personalized pricing is slightly different, these examples of computer-driven pricing have spawned headlines and social media posts that reflect a growing frustration with data’s role in how prices are dictated.</p>
<ul class="related">
<li><a href="https://thewalrus.ca/ai-is-coming-for-voice-actors-artists-everywhere-should-take-note/">AI Is Coming for Voice Actors. Artists Everywhere Should Take Note</a></li>
<li><a href="https://thewalrus.ca/will-ai-actually-mean-well-be-able-to-work-less/">Will AI Actually Mean We’ll Be Able to Work Less?</a></li>
<li><a href="https://thewalrus.ca/ai-poetry/">Robots Are Writing Poetry, and Many People Can’t Tell the Difference</a></li>
</ul>
<p>The marketplace is said to be a realm of assumed fairness, dictated by the rules of competition, an objective environment where one consumer is the same as any other. But this idea is being undermined by the same opaque and confusing programmatic data profiling that’s slowly encroaching on other parts of our lives&mdash;the algorithms. The Canadian government is currently considering new consumer-protection regulations, including what to do to control algorithm-based pricing. While strict market regulation is considered by some to be a political risk, another solution may exist&mdash;not at the point of sale but at the point where our data is gathered in the first place.</p>
<p>In theory, pricing algorithms aren’t necessarily bad. Prices that are more responsive to market forces and beyond human intervention could make some of the buying process more efficient and tailored to individual buyers. It might also result in pricing being clearer. And, technically speaking, by using data profiling to accurately assess a consumer’s willingness to pay (that is, the maximum amount someone would spend on something), personalized pricing could meet people where they are financially, creating more opportunity for some people to buy things they might otherwise not have been able to afford. </p>
<p>Again, that’s in theory. In practice, it sometimes works differently. Strange things can happen on the way to maximizing profits (<a href="https://www.teamly.com/blog/dynamic-pricing-algorithms/" rel="noopener" target="_blank">the goal</a> of pricing algorithms writ large). <a href="https://blogs.law.ox.ac.uk/business-law-blog/blog/2019/02/artificial-intelligence-algorithmic-pricing-and-collusion" rel="noopener" target="_blank">Researchers concluded in 2019</a> that “relatively simple pricing algorithms systematically learn to play collusive strategies” as they adjust to constantly meet changes made by others&mdash;even if they’re not designed to do so, nor are able to communicate with other pricing algorithms. <a href="https://www.nber.org/system/files/working_papers/w28860/w28860.pdf" rel="noopener" target="_blank">Researchers noted in 2021</a> that, under this scenario, “the largest gains accrue to a dominant firm with the most advanced technology and the largest market share.” </p>
<p>A <a href="https://mislove.org/publications/Amazon-WWW.pdf" rel="noopener" target="_blank">2016 study</a> that tracked for four months the top twenty Amazon sellers of over 1,600 products came to a similar conclusion. In some cases, algorithms were changing the prices of items “tens or even hundreds of times per day” (a frequency difficult for a human to replicate), creating “a largely winner-take-all marketplace.” The study showed these same sellers received more positive feedback, which put them at an advantage when it came to page ranks on Amazon. In other words, a site that appears to offer vast choices may, when driven by algorithms, end up offering only limited options from a few top sellers. Algorithms may also make things more expensive overall, as lowering prices might simply prompt competitors to undercut, decreasing the incentive for anyone to drop prices. If you feel like you’re spending more for things all the time, it might be because you are.</p>
<p>There is also a concern regarding biases inherent in big data. In 2015, ProPublica <a href="https://www.propublica.org/article/asians-nearly-twice-as-likely-to-get-higher-price-from-princeton-review" rel="noopener" target="_blank">revealed</a> that prices for the Princeton Review’s online SAT tutoring packages varied depending on US ZIP codes, creating the “unexpected effect&thinsp;.&thinsp;.&thinsp;.&thinsp;that Asians [were] almost twice as likely to be offered a higher price than non-Asians.”</p>
<p>All of which makes regulation necessary but simultaneously difficult&mdash;particularly if the issue is addressed at the point of sale. For example, a government could implement price controls for consumer goods, ensuring that we never pay more than a set rate (an idea that’s also been discussed recently as a temporary solution to rising grocery prices). But its implementation is not the norm, and its history would make it a hard sell politically. In fact, market regulation of any kind is likely to spark a backlash both from businesses that use tools like personalized pricing to increase profits and from opposition parties looking for ideological leverage. Given the recent history of the government’s update to the country’s broadcasting act&mdash;which also had at its core a question about the commercial value of data and which created a hyperactive discourse about censorship&mdash;a foray into personalized pricing regulation could prove too perilous to attempt.</p>
<p>The <a href="https://www.parl.ca/DocumentViewer/en/44-1/bill/C-19/royal-assent" rel="noopener" target="_blank">2022 federal budget bill</a> made updates to Canada’s Competition Act, but those amendments didn’t deal with algorithmic pricing directly, and a discussion paper released by Innovation, Science and Economic Development Canada noted that the act needs improvement due to “[t]he new challenges posed by how data-driven and digital markets operate.” There are “valid reasons to limit grounds for intervention in private commerce,” the paper went on but conceded that the question of how is growing increasingly complicated. “The public interest is not well-served if competitive harm is identifiable but the [Competition] Bureau is not sufficiently empowered to intervene.”</p>
<p>But there may be a way to limit the harms of algorithmic pricing other than by direct intervention against a seller. To get to the root of the issue, policy might be aimed much earlier in the shopping process and could focus on what personal data is available to sellers in the first place.</p>
<p>When it comes to our data, consumers are getting a raw deal in many instances, says Pascale Chapdelaine, associate professor at the University of Windsor Faculty of Law, who specializes in privacy and copyright and e-commerce law. For example, the idea of consent around personalized pricing “is very dubious,” she says, as it’s almost never explicitly brought to shoppers’ attention before checkout. Just by virtue of our being online, it’s possible that information about us is gathered without our informed or explicit opt-in and is used to dictate how much we pay at checkout. “How can you consent to something you don’t even understand in advance?” In many instances, the access we unknowingly grant to our personal data is “disproportionate&thinsp;.&thinsp;.&thinsp;.&thinsp;to what we’re going to get out of this” as consumers, Chapdelaine says. </p>
<p>One way to begin addressing the problem might be more transparency in stating that prices are being personalized by algorithms. But more transparency might simply raise awareness without fixing anything. Besides, people already know the computers are up to something. Instead, Chapdelaine advocates for legislating limits to the use of personal data that could be used to personalize prices, along with more enforcement from the courts and privacy commissioner.</p>
<p>For the government, the decision to curtail technology that businesses know can improve profit margins&mdash;particularly as many retailers and services are still recovering from pandemic losses&mdash;could be a risk, both politically and practically. But having been accused of losing touch with ordinary people&mdash;and specifically the bills they pay&mdash;the government may find that the benefits of tackling algorithmic pricing and introducing more fairness into our online marketplace outweigh the costs. </p>The post <a href="https://thewalrus.ca/computers-decide-cost/">Should Computers Decide How Much Things Cost?</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
		<item>
		<title>Could a New Religion Develop around AI?</title>
		<link>https://thewalrus.ca/ai-religion/</link>
		
		<dc:creator><![CDATA[Michael Coren]]></dc:creator>
		<pubDate>Thu, 29 Jun 2023 10:30:57 +0000</pubDate>
				<category><![CDATA[Technology]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[audio]]></category>
		<category><![CDATA[homepage]]></category>
		<category><![CDATA[religion]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=155931</guid>

		`

		<description><![CDATA[The hunger to believe in something beyond the self is real. What if bots started creating scripture?]]></description>
		<content:encoded><![CDATA[<img width="1600" height="1067" src="https://walrus-assets.s3.amazonaws.com/img/Coren_AIReligion_1800.jpg" class="webfeedsFeaturedVisual wp-post-image" alt="A photo illustration of a person wearing a white puffer jacket and a crucifix necklace." loading="lazy" style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/Coren_AIReligion_1800.jpg 1600w, https://walrus-assets.s3.amazonaws.com/img/Coren_AIReligion_1800-735x490.jpg 735w, https://walrus-assets.s3.amazonaws.com/img/Coren_AIReligion_1800-1536x1024.jpg 1536w, https://walrus-assets.s3.amazonaws.com/img/Coren_AIReligion_1800-1200x800.jpg 1200w, https://walrus-assets.s3.amazonaws.com/img/Coren_AIReligion_1800-348x232.jpg 348w" sizes="(max-width: 1600px) 100vw, 1600px" /><p><span class="dropcap">T</span><span class="smallcaps">he</span> picture of Pope Francis in a voluminous white puffer jacket jolted the religious as well as secular worlds. Within moments of its being posted at the end of March, social media was overrun with opinions. Supporters roared their approval, and opponents lamented yet another example of the pontiff selling out to modernity. Thing is, the photo wasn’t real. It was a deepfake, thereby becoming another reminder of the dangers of <a href="https://thewalrus.ca/tag/artificial-intelligence/" rel="noopener" target="_blank">artificial intelligence</a>: a fictitious portrayal of a world leader causing disunity among countless people.</p>
<p>These kinds of fabrications are part of what, that same month, led more than a thousand artificial intelligence experts to call for a temporary halt in the development of <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/" rel="noopener" target="_blank">&#8220;giant AI experiments&#8221;</a> until the technology can be made trustworthy. If unleashed without proper safeguards, commentators and critics argue, AI systems can destabilize and confuse; and as they learn and adapt and maybe even approach sentience, they could present a threat, perhaps an alternative, to humanity. </p>
<p>Sounds like the stuff of science fiction, but then, in these scenarios, it’s always the nerdy scientist or bumbling philosopher warning the world. “They should have listened!” we say as some calamity wipes away life as we know it. When it comes to AI, some people are listening, though&mdash;particularly those in organized religion, with its concern for human individuality, the uniqueness of the soul, and the embrace of a higher power.</p>
<p>Theologians and social commentators worry that a new religion could develop around an extreme reverence for AI. The essence of religion is faith: a leap of commitment to something beyond direct knowledge and a love for that which we can never completely understand. We can read the arguments and be convinced by the logic, but ultimately, we have to embrace that cloud of unknowing. </p>
<p>Not so with AI, where a religious aura could develop around a non-existent figure who appears on our screens and who seems all-knowing and all-understanding: all-knowing because it would have all of the information contained on the internet at its fingertips, all-understanding because your information will be there too&mdash;and often far more than you ever thought you had made public. “What is going to be created will effectively be a god,” former Google engineer Anthony Levandowski told <a href="https://www.wired.com/story/anthony-levandowski-artificial-intelligence-religion/" rel="noopener" target="_blank"><em>Wired</em></a> in 2017. “It’s not a god in the sense that it makes lightning or causes hurricanes. But if there is something a billion times smarter than the smartest human, what else are you going to call it?”</p>
<ul class="related">
<li><a href="https://thewalrus.ca/ai-is-coming-for-voice-actors-artists-everywhere-should-take-note/">AI Is Coming for Voice Actors. Artists Everywhere Should Take Note</a></li>
<li><a href="https://thewalrus.ca/fighting-ai-with-ai-the-battle-against-deepfakes/">Fighting AI with AI: The Battle against Deepfakes</a></li>
<li><a href="https://thewalrus.ca/how-we-made-ai-as-racist-and-sexist-as-humans/">How We Made AI As Racist and Sexist As Humans</a></li>
</li>
</ul>
<p>Is the deification of AI really so impossible? For the susceptible, instant communication with an entity representing a god, even God himself, could be transformative. And let’s be candid&mdash;those seeking certainty in faith can be particularly credulous. The philosopher Blaise Pascal is said to have written that there is a god-shaped hole in each of us. Not sure if I agree, but the hunger to believe in something beyond the self is real. The <em>New York Times</em> has reported on the “<a href="https://www.nytimes.com/interactive/2021/07/16/opinion/ai-ethics-religion.html" rel="noopener" target="_blank">pseudo-sacred industry</a>” and the rise of so-called social divinity consultants who help introduce spiritual practices into tech companies. The massive decline in traditional religious adherence, combined with a craving for some kind of faith, has led many to embrace alien life, new-age offerings, and dangerous cults. For historian and scholar Yuval Noah Harari, AI could be even more alluring, especially if it starts generating scripture. Then the tool’s oracular qualities can morph into a belief system that might spread and reshape society. “[R]eligions throughout history claimed that their holy books were written by unknown human intelligence,” Harari said at a recent science conference. “This was never true before. This could become true very, very quickly, with far-reaching consequences.”</p>
<p><span class="dropcap">W</span><span class="smallcaps">e</span> don&#8217;t have to wait for algorithms to conjure up a celestial figure. There’s plenty AI could disrupt right now, such as revolutionizing the structure of a standard religious service. Whatever the denomination, the sermon is the major part of any such gathering, and I can tell you, as someone who writes and delivers them on a weekly basis, that it’s a challenge to be original, fresh, and entertaining. </p>
<p>At the current level being provided by AI tools like ChatGPT and anticipating what can be expected even in the near future, AI could create figures capable of injecting emotion, inflection, and sincerity into a homily and have quick access to the contents of every religious commentary there is. It could also find jokes and witticisms and be able to make it all seem bitingly relevant through its knowledge of current events. It will also possess the thumping advantage of immediacy. Rabbi Joshua Franklin, who leads the Jewish Center of the Hamptons in East Hampton, posted on Vimeo a sermon written by ChatGPT he delivered last year. “You’re clapping,” Franklin told the congregation after he revealed the true author of the words he’d just spoken. “I’m deathly afraid.”</p>
<p>What can’t be provided, at least for the moment, is genuine personal contact and pastoral outreach. A great deal of the work of a priest is simple presence: being still and silent a few feet away from someone who is experiencing visceral grief or is in wounded need. But what we found during the pandemic-imposed Zoom years is that screen solidarity, while never quite the same thing as actually being there, was a good substitute. Now imagine an onscreen cleric on call, day or night, able to listen and respond and able to assimilate individual experiences and respond accordingly. The popularity of mental health chatbots suggests that this might not be too far fetched. And interestingly enough, GitaGPT, a recently launched chatbot, provides spiritual guidance by consulting the Hindu scripture the Bhagavad Gita.</p>
<p>My belief as an Anglican priest is that I’ve been given authority by my bishop through what we refer to as the apostolic succession. That enables me to call on the Holy Spirit during the Eucharistic service when I pray over the bread and wine. A layperson can’t do this, even a deacon can’t do this, and certainly not a non-human system. But maybe the lack of association with any organized worship works in AI’s favour. The technology would be a blank slate: an absence of malice, no history of harm. To be sure, there are justifiable concerns about the technology’s proneness to racist and discriminatory speech, shaped by the data it trains on. But we can surely imagine the opposite: an artificial entity that promotes itself as an expression of goodness and that, unlike religion down the ages, has never led Crusades, organized Inquisitions, or persecuted those with whom it differs. At least not yet. </p>
<p>Beyond all of this, however, is something more radical: the secular worship of AI itself. The idea, promoted by some techno-utopians, that such systems can solve any issue is maybe what we should really be fearing. Sam Altman, CEO of <a href="https://openai.com/" rel="noopener" target="_blank">OpenAI</a>, responsible for creating ChatGPT, said at a recent US senate hearing that his company “was founded on the belief that artificial intelligence has the ability to improve nearly every aspect of our lives.” Perhaps fantasy or foolishness gone wild, perhaps not. “Convince me it’s AI generated,” said one person on Twitter after the pope’s puffer coat revelation. If only it would stop at a coat. </p>The post <a href="https://thewalrus.ca/ai-religion/">Could a New Religion Develop around AI?</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
		<item>
		<title>Will Universal Basic Income Save Us from AI?</title>
		<link>https://thewalrus.ca/will-universal-basic-income-save-us-from-ai/</link>
		
		<dc:creator><![CDATA[Colin Horgan]]></dc:creator>
		<pubDate>Mon, 08 May 2023 10:30:52 +0000</pubDate>
				<category><![CDATA[Technology]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[audio]]></category>
		<category><![CDATA[homepage]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=154148</guid>

		`

		<description><![CDATA[OpenAI’s Sam Altman believes many jobs will soon vanish but UBI will be the solution. Other visions of the future are less rosy]]></description>
		<content:encoded><![CDATA[<img width="1600" height="1067" src="https://walrus-assets.s3.amazonaws.com/img/Horgan_UBI_1800.jpeg" class="webfeedsFeaturedVisual wp-post-image" alt="A photo illustration of a giant robot hand giving cash to a lineup of people." loading="lazy" style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/Horgan_UBI_1800.jpeg 1600w, https://walrus-assets.s3.amazonaws.com/img/Horgan_UBI_1800-735x490.jpeg 735w, https://walrus-assets.s3.amazonaws.com/img/Horgan_UBI_1800-1536x1024.jpeg 1536w, https://walrus-assets.s3.amazonaws.com/img/Horgan_UBI_1800-1200x800.jpeg 1200w, https://walrus-assets.s3.amazonaws.com/img/Horgan_UBI_1800-348x232.jpeg 348w" sizes="(max-width: 1600px) 100vw, 1600px" /><p><span class="dropcap">S</span><span class="smallcaps">am Altman,</span> CEO of OpenAI, has ideas about the future. One of them is about how you’ll make money. In short, you won’t necessarily have to, even if your job has been replaced by a powerful <a href="https://thewalrus.ca/tag/artificial-intelligence/" rel="noopener" target="_blank">artificial intelligence</a> tool. But what will be required for that purported freedom from the drudgery of work is living in a turbo-charged capitalist technocracy. “In the next five years, computer programs that can think will read legal documents and give medical advice,” Altman <a href="https://moores.samaltman.com/" rel="noopener" target="_blank">wrote in a 2021 post</a> called “Moore’s Law for Everything.” In another ten, “they will do assembly-line work and maybe even become companions.” Beyond that time frame, he wrote, “they will do almost everything.” In a world where computers do almost everything, what will humans be up to? </p>
<p>Looking for work, maybe. A <a href="https://www.key4biz.it/wp-content/uploads/2023/03/Global-Economics-Analyst_-The-Potentially-Large-Effects-of-Artificial-Intelligence-on-Economic-Growth-Briggs_Kodnani.pdf" rel="noopener" target="_blank">recent report</a> from Goldman Sachs estimates that generative AI “could expose the equivalent of 300 million full-time jobs to automation.” And while both Goldman and Altman believe that a lot of new jobs will be created along the way, it’s uncertain how that will look. “With every great technological revolution in human history&thinsp;.&thinsp;.&thinsp;.&thinsp;it has been true that the jobs change a lot, some jobs even go away&mdash;and I’m sure we’ll see a lot of that here,” Altman told <a href="https://www.youtube.com/watch?v=540vzMlf-54&#038;ab_channel=ABCNews" rel="noopener" target="_blank">ABC News</a> in March. Altman has imagined a solution to that problem for good reason: his company might create it.</p>
<p>In November, OpenAI released ChatGPT, a large language model chatbot that can mimic human conversations and written work. This spring, the company unveiled GPT-4, an even more powerful AI program that can do things like explain why <a href="https://openai.com/research/gpt-4" rel="noopener" target="_blank">a joke is funny</a> or <a href="https://www.nytimes.com/2023/03/14/technology/openai-new-gpt4.html" rel="noopener" target="_blank">plan a meal</a> by scanning a photo of the inside of someone’s fridge. Meanwhile, other major technology companies like Google and Meta are racing to catch up, sparking a so-called “<a href="https://www.nytimes.com/2023/02/03/technology/chatgpt-openai-artificial-intelligence.html" rel="noopener" target="_blank">AI arms race</a>” and, with it, the terror that many of us humans will very quickly be deemed too inefficient to keep around&mdash;at work anyway. </p>
<ul class="related">
<li><a href="https://thewalrus.ca/ai-is-coming-for-voice-actors-artists-everywhere-should-take-note/">AI Is Coming for Voice Actors. Artists Everywhere Should Take Note</a></li>
<li><a href="https://thewalrus.ca/will-ai-actually-mean-well-be-able-to-work-less/">Will AI Actually Mean We’ll Be Able to Work Less?</a></li>
<li><a href="https://thewalrus.ca/ai-poetry/">Robots Are Writing Poetry, and Many People Can’t Tell the Difference</a></li>
</ul>
<p>Altman’s solution to that problem is universal basic income, or UBI&mdash;giving people a guaranteed amount of money on a regular basis to either supplement their wages or to simply live off. “.&thinsp;.&thinsp;.&thinsp;a society that does not offer sufficient equality of opportunity for everyone to advance is not a society that will last,” Altman wrote in his 2021 blog post. Tax policy as we’ve known it will be even less capable of addressing inequalities in the future, he continued. “While people will still have jobs, many of those jobs won’t be ones that create a lot of economic value in the way we think of value today.” He proposed that, in the future&mdash;once AI “produces most of the world’s basic goods and services”&mdash;a fund could be created by taxing land and capital rather than labour. The dividends from that fund could be distributed to every individual to use as they please&mdash;“for better education, healthcare, housing, starting a company, whatever,” Altman wrote.  </p>
<p>UBI isn’t new. Forms of it have even been tested, including in Southern Ontario, where (under specific conditions) it produced <a href="https://labourstudies.socsci.mcmaster.ca/documents/southern-ontarios-basic-income-experience.pdf" rel="noopener" target="_blank">broadly positive impacts</a> on health and well-being. UBI also gained renewed attention during the COVID-19 pandemic as focus turned to precarious low-wage work, job losses, and emergency government assistance programs. Recently, in the <em><a href="https://www.wsj.com/articles/chatgpt-sam-altman-artificial-intelligence-openai-b0e1c8c9" rel="noopener" target="_blank">Wall Street Journal</a></em> and the <em><a href="https://www.nytimes.com/2023/03/31/technology/sam-altman-open-ai-chatgpt.html" rel="noopener" target="_blank">New York Times</a></em>, profiles of Altman raised the idea of UBI as a solution to massive job losses, with WSJ noting that Altman’s goal is to “free people to pursue more creative work.” In 2021, Altman was more specific, saying that advanced AI will allow people to “spend more time with people they care about, care for people, appreciate art and nature, or work toward social good.” But recent research and opinions offer a different, less rosy perspective on this UBI-based future.</p>
<p><span class="dropcap">I</span><span class="smallcaps">t might be more useful</span> to think about Altman’s UBI proposal as a solution in search of a problem. The concept helps Altman frame his vision of the future as a fait accompli, with UBI being some kind of end point we’ll inevitably reach. So it’s fair to wonder what the real goal of the UBI canard is for Altman. For one thing, it presupposes a power dynamic that benefits him and other existing tech giants. Second, it eliminates alternative options for a future world. </p>
<p>In reality, UBI may not even be necessary. OpenAI’s <a href="https://openai.com/research/gpts-are-gpts" rel="noopener" target="_blank">recent working paper</a>, which involved researchers from OpenResearch and the University of Pennsylvania, presents a different picture of the future of work. Yes, jobs will be impacted, the paper concluded. Approximately 80 percent of the US workforce “could have at least 10% of their work tasks affected by the introduction of LLMs (large language models),” the research found, with as many as 19 percent of workers having at least 50 percent of their tasks impacted. But how much or how little could depend on the role. If your work is “heavily reliant on science and critical thinking skills,” you might be less exposed than if you do things like programming or writing. In other words, despite economic and labour uncertainty&mdash;and the chorus of fear surrounding the current discourse on AI&mdash;humans will probably still work quite a bit in the future, just supported by forms of AI like LLMs. Even then, the researchers noted, the pace and scale to which AI is integrated into the economy will depend on the sector and on things like “data availability, regulatory environment, and the distribution of power and interests.”</p>
<p>Power and interests are, of course, what is at the heart of the idea of UBI as Altman presented it in 2021&mdash;a system in which the masses are merely shareholders in the wealth generated by AI mega corporations. Altman’s description of what UBI could do for us in the future (free up our time to work on art or to socialize) is at odds with the technocratic structure of the world he’s describing&mdash;dominated, as it would have to be, theoretically, by a small number of companies generating immense profits. In this scenario, those who still work would, presumably, be subject to significant power imbalances between themselves and their employers, as Australian researcher Lauren Kelly suggests in her 2022 paper on the future of work, published in the <em>Journal of Sociology</em>. In fact, the way Altman describes the future brings to mind something more current: social platform moderators. In these low-wage roles, often performed under reportedly dire conditions, human workers monitor and correct AI programs that are designed to filter out toxic content on social media platforms. From the outside, the AI programs appear automatic, intelligent, and nuanced. In reality, we’re seeing the results of human labour, referred to as “<a href="https://www.theverge.com/2019/5/13/18563284/mary-gray-ghost-work-microwork-labor-silicon-valley-automation-employment-interview" rel="noopener" target="_blank">ghost work</a>” because it’s unseen and unheard, hidden behind a veil of techno wonder. </p>
<p>It’s unclear how serious Altman is about creating this UBI-supported future. Though it’s been mentioned in recent interviews, it hasn’t featured significantly in OpenAI’s plans. As it happens, OpenAI’s “capped-profit” <a href="https://openai.com/blog/openai-lp" rel="noopener" target="_blank">structure</a> dictates that profits over a certain amount are owned by its nonprofit entity. When he was asked in January whether OpenAI planned to “take the proceeds that you’re presuming you’re going to make someday and&thinsp;.&thinsp;.&thinsp;.&thinsp;give them back to society,” Altman demurred. Yes, the company could distribute “cash for everyone,” he said. Or “we’re [going to] invest all of this in a non-profit that does a bunch of science.” He didn’t commit either way. The UBI plan will have to wait, it seems. </p>
<p>But we don’t have to wait for Altman to enact his grand vision. Instead, we could demand that the control of AI’s progress be shared more broadly and reflect goals other than those Altman and others articulate. We don’t need to sit by as AI overwhelms our professional or personal lives, hoping that a UBI scheme, offered as some kind of consolation, saves the day. As for the utopian vision where humans have more time to be creative or to spend with their loved ones in a clean, renewable future: why wait for a tech company to grant it to us? As Aaron Benanav, author of <em>Automation and the Future of Work</em>, <a href="https://www.versobooks.com/en-ca/products/2682-automation-and-the-future-of-work" rel="noopener" target="_blank">puts</a> it: “.&thinsp;.&thinsp;.&thinsp;all of this is possible now if we fight for it.”</p>The post <a href="https://thewalrus.ca/will-universal-basic-income-save-us-from-ai/">Will Universal Basic Income Save Us from AI?</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
		<item>
		<title>AI and Politics: How Will We Know What&#8212;and Who&#8212;Is Real?</title>
		<link>https://thewalrus.ca/ai-and-politics-how-will-we-know-what-and-who-is-real/</link>
		
		<dc:creator><![CDATA[Colin Horgan]]></dc:creator>
		<pubDate>Thu, 27 Apr 2023 10:30:44 +0000</pubDate>
				<category><![CDATA[Politics]]></category>
		<category><![CDATA[Technology]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[audio]]></category>
		<category><![CDATA[Canadian Politics]]></category>
		<category><![CDATA[homepage]]></category>
		<guid isPermaLink="false">https://thewalrus.ca/?p=153789</guid>

		`

		<description><![CDATA[If we’re lucky, new technologies will only cause brief confusion. If we’re not, our political sphere could be changed forever]]></description>
		<content:encoded><![CDATA[<img width="1600" height="1067" src="https://walrus-assets.s3.amazonaws.com/img/Horgan_AIPolitics_JarredBriggs_1800.jpeg" class="webfeedsFeaturedVisual wp-post-image" alt="An illustration of a person looking through binoculars. On the left lens is a reflection of a human, and on the right lens is a reflection of an AI-generated humanoid." loading="lazy" style="display: block; margin-bottom: 5px; clear:both;max-width: 100%;" link_thumbnail="" srcset="https://walrus-assets.s3.amazonaws.com/img/Horgan_AIPolitics_JarredBriggs_1800.jpeg 1600w, https://walrus-assets.s3.amazonaws.com/img/Horgan_AIPolitics_JarredBriggs_1800-735x490.jpeg 735w, https://walrus-assets.s3.amazonaws.com/img/Horgan_AIPolitics_JarredBriggs_1800-1536x1024.jpeg 1536w, https://walrus-assets.s3.amazonaws.com/img/Horgan_AIPolitics_JarredBriggs_1800-1200x800.jpeg 1200w, https://walrus-assets.s3.amazonaws.com/img/Horgan_AIPolitics_JarredBriggs_1800-348x232.jpeg 348w" sizes="(max-width: 1600px) 100vw, 1600px" /><p><span class="dropcap">I</span><span class="smallcaps">n January</span>, the Alberta Party, a centrist provincial party, posted a video on its official Instagram account. The since deleted video, which is still available on their <a href="https://twitter.com/AlbertaParty/status/1618644534682083328?s=20" rel="noopener" target="_blank">Twitter feed</a>, was of a man in a blue sweater facing the camera, with the Calgary skyline behind him. But something about him was off. “Does Alberta need a third political party? It depends on whether or not you’re happy with your current choices,” the man stated flatly, before suggesting Albertans seek “another option” on election day. His mouth didn’t form vowels properly. His face was strangely unmoving. And then there was his voice&mdash;it didn’t sound fully human.</p>
<p>That’s because it wasn’t. The video was <a href="https://thewalrus.ca/tag/artificial-intelligence/" rel="noopener" target="_blank">AI</a> generated. In a since deleted post, the Alberta Party clarified that “the face is an AI, but the words were written by a real person.” It was an unsettling episode, not unlike one from the hit techno-dystopian series <em>Black Mirror</em> in which a blue animated bear, Waldo, voiced by a comedian, runs as an anti-establishment candidate in a UK by-election.</p>
<p>“&thinsp;.&thinsp;.&thinsp;.&thinsp;wherever the people are well informed they can be trusted with their own government,” Thomas Jefferson <a href="https://www.loc.gov/exhibits/jefferson/60.html" rel="noopener" target="_blank">wrote</a> in the winter of 1789. In other words, in a democracy, being informed grants people agency, and having agency gives us a voice. AI has the potential to challenge both of these critical assumptions embedded for hundreds of years at the heart of our understanding of democracy. What happens when the loudest, or most influential, voice in politics is one created by a computer? And what happens when that computer-made voice also looks and sounds like a human? If we’re lucky, AI-generated or AI-manipulated audio and video will cause only brief moments of isolated confusion in our political sphere. If we’re not, there’s a risk it could upend politics&mdash;and society&mdash;permanently.</p>
<ul class="related">
<li><a href="https://thewalrus.ca/vote-efficiency-federal-elections/">The Ruthless Math of Political Campaigns: Is Big Data Bad for Democracy?</a></li>
<li><a href="https://thewalrus.ca/ai-is-coming-for-voice-actors-artists-everywhere-should-take-note/">AI Is Coming for Voice Actors. Artists Everywhere Should Take Note</a></li>
<li><a href="https://thewalrus.ca/will-ai-actually-mean-well-be-able-to-work-less/">Will AI Actually Mean We’ll Be Able to Work Less?</a></li>
</ul>
<p>Much of our fate hinges on our familiarity with what we’re seeing. Take bots, for instance. These automated or semi-automated programs are powered by AI, and <a href="https://thewalrus.ca/tag/social-media/" rel="noopener" target="_blank">social media</a> platforms are already replete with them. They are commonly used to fake follower counts, auto-respond to customer queries, and provide breaking news updates. More concerningly, they’re also used in campaigns to either influence public debate or, in some cases, harass people. But these kinds of bots remain text based. What the Alberta Party created, and what others are making, is much different. It challenges what we see and hear.</p>
<p>In 2018, actor and director Jordan Peele allowed his voice to be digitally altered and then grafted onto a manipulated video of Barack Obama so that <a href="https://www.buzzfeednews.com/article/davidmack/obama-fake-news-jordan-peele-psa-video-buzzfeed#.gcxNolpGL" rel="noopener" target="_blank">it looked like</a> the former US president was actually speaking Peele’s script. This kind of video is made with generative AI and is called a “deepfake.” Peele’s was created as a warning against the potential for sophisticated misinformation campaigns in the future, including the 2020 US election. But that election passed without any significant AI-induced confusion. Instead, “simple deceptions like selective editing or outright lies have worked just fine,” NPR <a href="https://www.npr.org/2020/10/01/918223033/where-are-the-deepfakes-in-this-presidential-election" rel="noopener" target="_blank">concluded</a> that year in an attempt to explain the lack of deepfakes. </p>
<p>But, at the time, there were technical and cost limitations. “It’s not like you can just download one app and&thinsp;.&thinsp;.&thinsp;.&thinsp;provide something like a script and create a deepfake format and make [an individual] say this,” one expert told the broadcaster. “Perhaps we will [get to that point] over the next few years, then it’s going to be very easy, potentially, to create compelling manipulations.” </p>
<p>We’re there now. </p>
<p><span class="dropcap">I</span><span class="smallcaps">n February</span>, an Instagram account posted a video purportedly of President Joe Biden making offensive remarks about transgender women. The audio had been generated using an AI program that mimics real voices. It was flagged on social media as an “altered video,” but it gained traction and was reposted by some right-wing American media outlets. Even Biden’s supporters have taken to doctoring his voice. “I ran into a very important friend over the weekend,” <em>Pod Save America</em> co-host Tommy Vietor, a White House staffer during the Obama administration, said in a <a href="https://podcasts.apple.com/us/podcast/the-2024-dry-ron/id1192761536?i=1000602015326" rel="noopener" target="_blank">recent episode</a>, before playing a clip of what sounded like Biden. Vietor quickly admitted he’d paid $5 at <em>elevenlabs.com</em> to make the clip. </p>
<p>There’s an important difference between what the Alberta Party posted&mdash;a person created entirely by a computer&mdash;and the synthesized audio-visual representation of a real human, like the sitting president, in a deepfake. Still, the reaction to each is similar: people get confused. One reason for that is unfamiliarity. “One of the key things is&thinsp;.&thinsp;.&thinsp;.&thinsp;digital literacy from a public perspective,” says Elizabeth Dubois, university research chair in politics, communication, and technology and associate professor at the University of Ottawa. “As these innovations become more embedded in campaigns&thinsp;.&thinsp;.&thinsp;.&thinsp;people will generally become literate about what’s happening and how things are showing up on their screen. But in these early stages where this experimentation is happening, that’s when we see the most chance for people to just not really understand what’s going on.”</p>
<p>But the media under manipulation is also important. By doctoring video and audio, these videos upend social expectations about the relationship both have with objective truth, says Regina Rini, Canada research chair in social reasoning at York University. Technically, bots say things verbally&mdash;or using text. And while we generally have an innate understanding that verbal or written statements can be untrue or mistaken or deceptive, Rini says, we’re less inclined to be as skeptical in case of audio-visual media. “Everyone knows it’s possible to fake traditional photos.&thinsp;.&thinsp;.&thinsp;.&thinsp;We’ve known it’s possible to tinker with videos,” says Rini. “But the degree of&thinsp;.&thinsp;.&thinsp;.&thinsp;default skepticism has been a lot lower for audio and video recordings.” Generative AI is changing that. </p>
<p>It’s possible that the gradual introduction of AI-manipulated video and audio in everyday discourse will acclimatize the general public to it in the same way that we became accustomed to text-based bots. On the other hand, all hell could break loose if a large number of people are required to assess the authenticity of a video or audio clip before we’re ready. A nightmare scenario, says Rini by way of an example, is if a deceptive video with significant geopolitical implications were to go viral, such as a fake conversation between Joe Biden and Vladimir Putin&mdash;“you know, the kind of thing that can start wars.” But even a slow drip could erode the foundation of our shared reality. “The thing that scares me is that we don’t fall for them, or most of us don’t fall for them, but they just continuously pop up one by one over time. And we’re constantly fighting over whether or not we believe in the latest instance of media,” Rini says. “That cumulative effect over time of lots of little instances of that, and some big ones too, eventually to build up to the point where we stop trusting media in general.”</p>
<p>If you think this is far-fetched, consider an example from just outside the political realm. In March, a video clip from something called the Caba Baba Rave circulated on Twitter, amplified by right-wing accounts like Libs of TikTok. Caba Baba Rave is a UK-based drag cabaret. The viral video showed an event where drag and non-binary performers put on a show for parents of very young children. Caba Baba Rave called it “a cabaret show designed for parents, with sensory moments for babies.” The clip caused an uproar, not just because of its content but also claims that the video was doctored. Soon enough, an entire sub-discourse erupted about whether someone had doctored the video to make an ideological point. But the video was real, as Caba Baba Rave confirmed. In spite of that, some users still didn’t believe it was.</p>
<p>Even when social media users aren’t convinced videos are deepfakes or otherwise doctored, the levels of scrutiny currently devoted to just the most benign clips, particularly on TikTok, suggest an insatiable appetite for debate over the veracity of video and audio. In other words, the internet has been primed for exactly the kind of fight Rini warns against&mdash;an endless war of meta skepticism. </p>
<p><span class="dropcap">T</span><span class="smallcaps">here’s another</span>, less public way that we may reach a point where the framework of reality starts to bend beyond our understanding. While AI changes the terms of the public debate online, it will be deployed in ways that are less visible too. </p>
<p>It’s already possible for avenues of public consultation, including social media, to be flooded with bot-generated messages, but AI offers potentially more effective, not to mention vexing, scenarios. Here’s one <a href="https://arxiv.org/pdf/2110.09231.pdf" rel="noopener" target="_blank">outlined in research</a> released in February from Nathan E. Sanders, a data scientist at the Berkman Klein Center at Harvard University, and Bruce Schneier, a security technologist at the Harvard Kennedy School. A political actor (let’s say a lobbying firm with deep pockets) creates a machine-learning program designed to graph a network of legislators based on their position, seniority, level, past voting trend, statements, or a multitude of other factors, allowing the firm to concentrate their lobbying efforts on those politicians predicted to have the most influence on a given legislative strategy. </p>
<p>The kind of tool Vietor showcased on the podcast introduces an even more bizarre possibility. Maybe you wrap that predictive machine-learning model into a system that has the ability to phone a politician’s office and carry out a conversation about that legislation using an automated, synthesized voice. And maybe that voice sounds a lot like one of their constituents. Or the prime minister’s.</p>
<p>“How do you prevent that from biasing, distorting our political process?” Sanders asked during our conversation. “Our fundamental recommendation in that regime is to make it easier for people to participate.&thinsp;.&thinsp;.&thinsp;.&thinsp;Make it easier for real people to have their voice heard as well.” Sanders pointed out that some AI tools are already doing that, including ones like Google Translate, which make it simpler for some people to get in touch with their representative by translating messages from their language to their representative’s language.</p>
<p>To be clear, technology is no stranger to politics. “We should expect that, with any new technologies, people are going to try and figure out whether or not there’s a way to make politics better, more effective, cheaper,” says Dubois. Sanders echoes this, pointing to existing tools like mail merge, a method for sending personalized messages in bulk, that political parties and candidates have used for many years. “I don’t think it’s really that different from using the AI tool to take, you know, three or four facts about you and then trying to generate a more personalized message.” </p>
<p>In Canada, rules dictating AI use during a political campaign aren’t specifically articulated in the Elections Act. But Elections Canada does have rules against impersonation or false representation with the intent to mislead. “Misleading publications” are also prohibited&mdash;that’s “any material, regardless of its form” that purports to be from the chief electoral officer, returning officer, or political candidate. Other than in instances that might relate to impersonation or misleading publication, Elections Canada does not “actively look for deepfakes, fake images and videos,” the agency said in an email. </p>
<p>But Elections Canada is only concerned with election periods. Government legislation would cover everything else. However, the use of AI for political purposes doesn’t appear to be mentioned in Canada’s new AI law that is moving through Parliament, and an email to the office of the minister for innovation, science, and industry, seeking clarification, went unanswered.</p>
<p>For Mark Coeckelbergh, professor of the philosophy of media and technology at the University of Vienna, AI may help push typical persuasion into more negative territory. Politicians naturally try to influence us, he says, but “the problem with many of these technologies is that they enable the more manipulative side rather than persuasion by argument and information,” he says. “What you’re doing is you’re treating people not as autonomous, enlightened kind of subjects&thinsp;.&thinsp;.&thinsp;.&thinsp;you’re treating them like lab rats or any kind of thing you can take data [from] and you can manipulate.”</p>
<p>How far could that manipulation really go? Politicians and political candidates are already capable of lying to voters. In one recent high-profile case, Republican George Santos admitted that his résumé, on the basis of which he campaigned for&mdash;and won&mdash;a seat in the US House of Representatives, was filled with fabrications, including about his education and work experience. If a real-life human can deceive voters so easily, could a fabricated one do the same?</p>
<p>Last year, the Synthetic Party, a Danish party founded by an artist collective and tech organization, <a href="https://www.vice.com/en/article/jgpb3p/this-danish-political-party-is-led-by-an-ai" rel="noopener" target="_blank">drew attention</a> for trying to run candidates led by an AI chat bot named Leader Lars. To run an actual AI-generated candidate in a riding in Canada would likely require some level of fraud. However, the toughest barriers to navigate&mdash;identification (the list of acceptable documents is long and not all require a photo) and the recommended 150 signatures from riding residents&mdash;are not insurmountable. Campaigning would be via social media. Debates could be ignored, as they sometimes are by real candidates. Under these circumstances, could an AI-generated candidate convince people to vote for it without them realizing it was fake?</p>
<p>Sanders doesn’t think a full AI candidate would pass muster. “I think, in general, it won’t be possible,” he says, noting that we as a society would be able to catch something like this before it happens. Dubois suggests what she sees as a more likely scenario: parody content, like the fake clip of Joe Biden, gets mistaken for communication from a real candidate. “We know that when people are scrolling quickly, they sometimes get confused, they don’t notice the label, they think it’s really funny, so they’re going to share it anyway,” she says. “And then, because they shared it, they are a trusted source to someone else, and then somebody else sees it. So you could imagine that sort of knock-on effect.”</p>
<p>“I think someone will try it, perhaps as a stunt,” says Rini, adding that its success might be geography dependent, like in a rural area where voters might be less likely to attend in-person events. Or it might just be about finding the right opportunity and party. “If you targeted an extremely uncompetitive house seat in the United States&thinsp;.&thinsp;.&thinsp;.&thinsp;and for whatever reason the primary wasn’t closely contested, [it] might not be hard to pull this off.” Canada’s bilingual political scene may offer a different kind of opportunity&mdash;not to fabricate a candidate but rather language, with a deepfake that makes an anglophone candidate fluent in French. For his part, Coeckelbergh is more certain about the possibility of an AI-generated candidate. “Absolutely. It’s going to happen.” </p>
<p>In fact, one might not even need to hide it. About two-thirds of the way through <em>Black Mirror</em>’s “The Waldo Moment,” a TV executive, Jack, argues with the cartoon bear’s human creator and voice, Jamie, about Waldo’s legitimacy as a candidate. “Waldo’s not real!” Jamie says. “Exactly&thinsp;.&thinsp;.&thinsp;.&thinsp;He’s not real, but he’s realer than all the others,” Jack replies. “He doesn’t stand for anything,” Jamie says. “Well, at least he doesn’t pretend to!” says Jack. </p>
<p>There’s a chance we’ll all end up siding with Jack, no longer debating about our political beliefs but whether we can believe&mdash;let alone believe in&mdash;anything at all. There’s also a chance we might prefer this debate to one about reality. We may find it more engaging anyway. </p>The post <a href="https://thewalrus.ca/ai-and-politics-how-will-we-know-what-and-who-is-real/">AI and Politics: How Will We Know What—and Who—Is Real?</a> first appeared on <a href="https://thewalrus.ca">The Walrus</a>.]]></content:encoded>

		
		
			</item>
	</channel>
</rss>


<!--
Performance optimized by W3 Total Cache. Learn more: https://www.boldgrid.com/w3-total-cache/

Object Caching 43/395 objects using disk
Page Caching using disk: enhanced (SSL caching disabled) 
Lazy Loading (feed)
Minified using disk

Served from: thewalrus.ca @ 2023-11-18 03:56:36 by W3 Total Cache
-->